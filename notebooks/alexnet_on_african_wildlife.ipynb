{"cells":[{"cell_type":"markdown","metadata":{},"source":["> The notebook was used on kaggle but if the paths are properly defined, it can be used to train other image classification models on any ImageFolder dataset. The modular codes are available in the modular code folders. It just needs to be adapted for the specific task in mind. "]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:19:22.570908Z","iopub.status.busy":"2024-02-14T17:19:22.570531Z","iopub.status.idle":"2024-02-14T17:19:28.827961Z","shell.execute_reply":"2024-02-14T17:19:28.826948Z","shell.execute_reply.started":"2024-02-14T17:19:22.570878Z"},"trusted":true},"outputs":[],"source":["import torch"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:19:28.830282Z","iopub.status.busy":"2024-02-14T17:19:28.829718Z","iopub.status.idle":"2024-02-14T17:19:28.889827Z","shell.execute_reply":"2024-02-14T17:19:28.888515Z","shell.execute_reply.started":"2024-02-14T17:19:28.830247Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'cuda'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Setup device agnostic code\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:19:28.891447Z","iopub.status.busy":"2024-02-14T17:19:28.891159Z","iopub.status.idle":"2024-02-14T17:19:30.066330Z","shell.execute_reply":"2024-02-14T17:19:30.065177Z","shell.execute_reply.started":"2024-02-14T17:19:28.891423Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Wed Feb 14 17:19:29 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   57C    P8              11W /  70W |      3MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","|   1  Tesla T4                       Off | 00000000:00:05.0 Off |                    0 |\n","| N/A   57C    P8              10W /  70W |      3MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:19:30.069995Z","iopub.status.busy":"2024-02-14T17:19:30.069538Z","iopub.status.idle":"2024-02-14T17:19:34.833647Z","shell.execute_reply":"2024-02-14T17:19:34.832866Z","shell.execute_reply.started":"2024-02-14T17:19:30.069946Z"},"trusted":true},"outputs":[],"source":["import os\n","\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import v2\n","\n","NUM_WORKERS = os.cpu_count()\n","\n","def create_dataloaders(\n","    train_dir: str, \n","    test_dir: str, \n","    transform: v2.Compose, \n","    batch_size: int, \n","    num_workers: int=NUM_WORKERS\n","):\n","  \"\"\"Creates training and testing DataLoaders.\n","\n","  Takes in a training directory and testing directory path and turns\n","  them into PyTorch Datasets and then into PyTorch DataLoaders.\n","\n","  Args:\n","    train_dir: Path to training directory.\n","    test_dir: Path to testing directory.\n","    transform: torchvision transforms to perform on training and testing data.\n","    batch_size: Number of samples per batch in each of the DataLoaders.\n","    num_workers: An integer for number of workers per DataLoader.\n","\n","  Returns:\n","    A tuple of (train_dataloader, test_dataloader, class_names).\n","    Where class_names is a list of the target classes.\n","    Example usage:\n","      train_dataloader, test_dataloader, class_names = \\\n","        = create_dataloaders(train_dir=path/to/train_dir,\n","                             test_dir=path/to/test_dir,\n","                             transform=some_transform,\n","                             batch_size=32,\n","                             num_workers=4)\n","  \"\"\"\n","  # Use ImageFolder to create dataset(s)\n","  train_data = datasets.ImageFolder(train_dir, transform=transform)\n","  test_data = datasets.ImageFolder(test_dir, transform=transform)\n","\n","  # Get class names\n","  class_names = train_data.classes\n","\n","  # Turn images into data loaders\n","  train_dataloader = DataLoader(\n","      train_data,\n","      batch_size=batch_size,\n","      shuffle=True,\n","      num_workers=num_workers,\n","      pin_memory=True,\n","  )\n","  test_dataloader = DataLoader(\n","      test_data,\n","      batch_size=batch_size,\n","      shuffle=False,\n","      num_workers=num_workers,\n","      pin_memory=True,\n","  )\n","\n","  return train_dataloader, test_dataloader, class_names"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:19:34.835700Z","iopub.status.busy":"2024-02-14T17:19:34.835032Z","iopub.status.idle":"2024-02-14T17:19:34.858308Z","shell.execute_reply":"2024-02-14T17:19:34.857448Z","shell.execute_reply.started":"2024-02-14T17:19:34.835663Z"},"trusted":true},"outputs":[],"source":["from typing import Dict, List, Tuple\n","\n","import torch\n","\n","from tqdm.auto import tqdm\n","\n","def train_step(model: torch.nn.Module, \n","               dataloader: torch.utils.data.DataLoader, \n","               loss_fn: torch.nn.Module, \n","               optimizer: torch.optim.Optimizer,\n","               device: torch.device) -> Tuple[float, float]:\n","    \"\"\"Trains a PyTorch model for a single epoch.\n","\n","    Turns a target PyTorch model to training mode and then\n","    runs through all of the required training steps (forward\n","    pass, loss calculation, optimizer step).\n","\n","    Args:\n","    model: A PyTorch model to be trained.\n","    dataloader: A DataLoader instance for the model to be trained on.\n","    loss_fn: A PyTorch loss function to minimize.\n","    optimizer: A PyTorch optimizer to help minimize the loss function.\n","    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n","\n","    Returns:\n","    A tuple of training loss and training accuracy metrics.\n","    In the form (train_loss, train_accuracy). For example:\n","\n","    (0.1112, 0.8743)\n","    \"\"\"\n","    # Put model in train mode\n","    model.train()\n","\n","    # Setup train loss and train accuracy values\n","    train_loss, train_acc = 0, 0\n","\n","    # Loop through data loader data batches\n","    for batch, (X, y) in enumerate(dataloader):\n","        # Send data to target device\n","        X, y = X.to(device), y.to(device)\n","\n","        # 1. Forward pass\n","        y_pred = model(X)\n","\n","        # 2. Calculate  and accumulate loss\n","        loss = loss_fn(y_pred, y)\n","        train_loss += loss.item() \n","\n","        # 3. Optimizer zero grad\n","        optimizer.zero_grad()\n","\n","        # 4. Loss backward\n","        loss.backward()\n","\n","        # 5. Optimizer step\n","        optimizer.step()\n","\n","        # Calculate and accumulate accuracy metric across all batches\n","        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n","        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n","\n","    # Adjust metrics to get average loss and accuracy per batch \n","    train_loss = train_loss / len(dataloader)\n","    train_acc = train_acc / len(dataloader)\n","    return train_loss, train_acc\n","\n","def test_step(model: torch.nn.Module, \n","              dataloader: torch.utils.data.DataLoader, \n","              loss_fn: torch.nn.Module,\n","              device: torch.device) -> Tuple[float, float]:\n","    \"\"\"Tests a PyTorch model for a single epoch.\n","\n","    Turns a target PyTorch model to \"eval\" mode and then performs\n","    a forward pass on a testing dataset.\n","\n","    Args:\n","    model: A PyTorch model to be tested.\n","    dataloader: A DataLoader instance for the model to be tested on.\n","    loss_fn: A PyTorch loss function to calculate loss on the test data.\n","    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n","\n","    Returns:\n","    A tuple of testing loss and testing accuracy metrics.\n","    In the form (test_loss, test_accuracy). For example:\n","\n","    (0.0223, 0.8985)\n","    \"\"\"\n","    # Put model in eval mode\n","    model.eval() \n","\n","    # Setup test loss and test accuracy values\n","    test_loss, test_acc = 0, 0\n","\n","    # Turn on inference context manager\n","    with torch.inference_mode():\n","        # Loop through DataLoader batches\n","        for batch, (X, y) in enumerate(dataloader):\n","            # Send data to target device\n","            X, y = X.to(device), y.to(device)\n","\n","            # 1. Forward pass\n","            test_pred_logits = model(X)\n","\n","            # 2. Calculate and accumulate loss\n","            loss = loss_fn(test_pred_logits, y)\n","            test_loss += loss.item()\n","\n","            # Calculate and accumulate accuracy\n","            test_pred_labels = test_pred_logits.argmax(dim=1)\n","            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n","\n","    # Adjust metrics to get average loss and accuracy per batch \n","    test_loss = test_loss / len(dataloader)\n","    test_acc = test_acc / len(dataloader)\n","    return test_loss, test_acc\n","\n","def train(model: torch.nn.Module, \n","          train_dataloader: torch.utils.data.DataLoader, \n","          test_dataloader: torch.utils.data.DataLoader, \n","          optimizer: torch.optim.Optimizer,\n","          loss_fn: torch.nn.Module,\n","          epochs: int,\n","          device: torch.device) -> Dict[str, List[float]]:\n","    \"\"\"Trains and tests a PyTorch model.\n","\n","    Passes a target PyTorch models through train_step() and test_step()\n","    functions for a number of epochs, training and testing the model\n","    in the same epoch loop.\n","\n","    Calculates, prints and stores evaluation metrics throughout.\n","\n","    Args:\n","    model: A PyTorch model to be trained and tested.\n","    train_dataloader: A DataLoader instance for the model to be trained on.\n","    test_dataloader: A DataLoader instance for the model to be tested on.\n","    optimizer: A PyTorch optimizer to help minimize the loss function.\n","    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n","    epochs: An integer indicating how many epochs to train for.\n","    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n","\n","    Returns:\n","    A dictionary of training and testing loss as well as training and\n","    testing accuracy metrics. Each metric has a value in a list for \n","    each epoch.\n","    In the form: {train_loss: [...],\n","              train_acc: [...],\n","              test_loss: [...],\n","              test_acc: [...]} \n","    For example if training for epochs=2: \n","             {train_loss: [2.0616, 1.0537],\n","              train_acc: [0.3945, 0.3945],\n","              test_loss: [1.2641, 1.5706],\n","              test_acc: [0.3400, 0.2973]} \n","    \"\"\"\n","    # Create empty results dictionary\n","    results = {\"train_loss\": [],\n","               \"train_acc\": [],\n","               \"test_loss\": [],\n","               \"test_acc\": []\n","    }\n","\n","    # Loop through training and testing steps for a number of epochs\n","    for epoch in tqdm(range(epochs)):\n","        train_loss, train_acc = train_step(model=model,\n","                                          dataloader=train_dataloader,\n","                                          loss_fn=loss_fn,\n","                                          optimizer=optimizer,\n","                                          device=device)\n","        test_loss, test_acc = test_step(model=model,\n","          dataloader=test_dataloader,\n","          loss_fn=loss_fn,\n","          device=device)\n","\n","        # Print out what's happening\n","        print(\n","          f\"Epoch: {epoch+1} | \"\n","          f\"train_loss: {train_loss:.4f} | \"\n","          f\"train_acc: {train_acc:.4f} | \"\n","          f\"test_loss: {test_loss:.4f} | \"\n","          f\"test_acc: {test_acc:.4f}\"\n","        )\n","\n","        # Update results dictionary\n","        results[\"train_loss\"].append(train_loss)\n","        results[\"train_acc\"].append(train_acc)\n","        results[\"test_loss\"].append(test_loss)\n","        results[\"test_acc\"].append(test_acc)\n","\n","    # Return the filled results at the end of the epochs\n","    return results"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:19:34.860146Z","iopub.status.busy":"2024-02-14T17:19:34.859890Z","iopub.status.idle":"2024-02-14T17:19:34.879863Z","shell.execute_reply":"2024-02-14T17:19:34.878922Z","shell.execute_reply.started":"2024-02-14T17:19:34.860124Z"},"trusted":true},"outputs":[],"source":["input_folder = \"/kaggle/input/african-wildlife\"\n","output = \"/kaggle/working/\""]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:19:34.882484Z","iopub.status.busy":"2024-02-14T17:19:34.880971Z","iopub.status.idle":"2024-02-14T17:19:49.697844Z","shell.execute_reply":"2024-02-14T17:19:49.696881Z","shell.execute_reply.started":"2024-02-14T17:19:34.882459Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting split-folders[full]\n","  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from split-folders[full]) (4.66.1)\n","Installing collected packages: split-folders\n","Successfully installed split-folders-0.5.1\n"]}],"source":["# importing split-folders to split my dataset\n","!pip install split-folders[full]"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:19:49.699945Z","iopub.status.busy":"2024-02-14T17:19:49.699495Z","iopub.status.idle":"2024-02-14T17:20:18.051035Z","shell.execute_reply":"2024-02-14T17:20:18.050094Z","shell.execute_reply.started":"2024-02-14T17:19:49.699893Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Copying files: 3008 files [00:28, 106.19 files/s]\n"]}],"source":["import splitfolders\n","\n","# Split with a ratio.\n","# To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\n","splitfolders.ratio(input_folder, output=output,\n","    seed=1337, ratio=(.8, .2), group_prefix=None, move=False) # default values\n","\n","# Split val/test with a fixed number of items, e.g. `(100, 100)`, for each set.\n","# To only split into training and validation set, use a single number to `fixed`, i.e., `10`.\n","# Set 3 values, e.g. `(300, 100, 100)`, to limit the number of training values.\n","# splitfolders.fixed(\"input_folder\", output=\"output\",\n","#     seed=1337, fixed=(100, 100), oversample=False, group_prefix=None, move=False) # default values"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:20:18.052571Z","iopub.status.busy":"2024-02-14T17:20:18.052271Z","iopub.status.idle":"2024-02-14T17:20:18.056719Z","shell.execute_reply":"2024-02-14T17:20:18.055898Z","shell.execute_reply.started":"2024-02-14T17:20:18.052544Z"},"trusted":true},"outputs":[],"source":["# Set up train and test dirs\n","train_dir = \"/kaggle/working/train\"\n","test_dir = \"/kaggle/working/val\""]},{"cell_type":"markdown","metadata":{},"source":["## Prepare Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:20:18.061457Z","iopub.status.busy":"2024-02-14T17:20:18.061127Z","iopub.status.idle":"2024-02-14T17:20:18.122410Z","shell.execute_reply":"2024-02-14T17:20:18.121516Z","shell.execute_reply.started":"2024-02-14T17:20:18.061432Z"},"trusted":true},"outputs":[],"source":["import os\n","\n","# remoing all the .txt file\n","# Replace with the actual path to your dataset directory\n","path_to_your_data = '/kaggle/working/'\n","\n","# Walk through the directory\n","for root, dirs, files in os.walk(path_to_your_data):\n","    for file in files:\n","        # Check if the file is a .txt file\n","        if file.endswith('.txt'):\n","            # Construct the full file path\n","            path_to_file = os.path.join(root, file)\n","            # Remove the file\n","            os.remove(path_to_file)\n","        \n"]},{"cell_type":"markdown","metadata":{},"source":["# Get a Pretrained model"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:20:18.124125Z","iopub.status.busy":"2024-02-14T17:20:18.123865Z","iopub.status.idle":"2024-02-14T17:20:20.757556Z","shell.execute_reply":"2024-02-14T17:20:20.756766Z","shell.execute_reply.started":"2024-02-14T17:20:18.124101Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n","100%|██████████| 233M/233M [00:01<00:00, 172MB/s]  \n"]}],"source":["import torchvision\n","# Setup the model with pretrained weights and send it to the target device\n","weights = torchvision.models.AlexNet_Weights.DEFAULT # best available weight\n","#transform = torchvision.models.AlexNet_Weights.IMAGENET1K_V1.transforms \n","model_0 = torchvision.models.alexnet(weights=weights).to(device)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:20:20.759506Z","iopub.status.busy":"2024-02-14T17:20:20.758811Z","iopub.status.idle":"2024-02-14T17:20:20.777969Z","shell.execute_reply":"2024-02-14T17:20:20.777222Z","shell.execute_reply.started":"2024-02-14T17:20:20.759470Z"},"trusted":true},"outputs":[],"source":["# Try to get torchinfo, install it if it doesn't work\n","try:\n","    from torchinfo import summary\n","except:\n","    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n","    !pip install -q torchinfo\n","    from torchinfo import summary"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:38:36.533313Z","iopub.status.busy":"2024-02-14T17:38:36.532642Z","iopub.status.idle":"2024-02-14T17:38:36.537908Z","shell.execute_reply":"2024-02-14T17:38:36.536923Z","shell.execute_reply.started":"2024-02-14T17:38:36.533282Z"},"trusted":true},"outputs":[],"source":["# # Create simple transform\n","data_transform = transforms.Compose([ \n","    transforms.Resize((64, 64)),\n","    transforms.ToTensor(),\n","    \n","])\n"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:38:51.827992Z","iopub.status.busy":"2024-02-14T17:38:51.827374Z","iopub.status.idle":"2024-02-14T17:38:51.843486Z","shell.execute_reply":"2024-02-14T17:38:51.842587Z","shell.execute_reply.started":"2024-02-14T17:38:51.827961Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(<torch.utils.data.dataloader.DataLoader at 0x7fcb52da3a30>,\n"," <torch.utils.data.dataloader.DataLoader at 0x7fcb185d9d50>,\n"," ['buffalo', 'elephant', 'rhino', 'zebra'])"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["# Create training and testing DataLoader's as well as get a list of class names\n","train_dataloader, test_dataloader, class_names = create_dataloaders(train_dir=train_dir,\n","                                                                               test_dir=test_dir,\n","                                                                               transform= data_transform,\n","                                                                               batch_size=32) # set mini-batch size to 32\n","\n","train_dataloader, test_dataloader, class_names"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:38:55.256673Z","iopub.status.busy":"2024-02-14T17:38:55.255880Z","iopub.status.idle":"2024-02-14T17:38:55.319699Z","shell.execute_reply":"2024-02-14T17:38:55.318862Z","shell.execute_reply.started":"2024-02-14T17:38:55.256638Z"},"trusted":true},"outputs":[{"data":{"text/plain":["===================================================================================================================\n","Layer (type:depth-idx)                   Input Shape               Output Shape              Trainable\n","===================================================================================================================\n","AlexNet                                  [32, 3, 224, 224]         [32, 4]                   Partial\n","├─Sequential: 1-1                        [32, 3, 224, 224]         [32, 256, 6, 6]           False\n","│    └─Conv2d: 2-1                       [32, 3, 224, 224]         [32, 64, 55, 55]          False\n","│    └─ReLU: 2-2                         [32, 64, 55, 55]          [32, 64, 55, 55]          --\n","│    └─MaxPool2d: 2-3                    [32, 64, 55, 55]          [32, 64, 27, 27]          --\n","│    └─Conv2d: 2-4                       [32, 64, 27, 27]          [32, 192, 27, 27]         False\n","│    └─ReLU: 2-5                         [32, 192, 27, 27]         [32, 192, 27, 27]         --\n","│    └─MaxPool2d: 2-6                    [32, 192, 27, 27]         [32, 192, 13, 13]         --\n","│    └─Conv2d: 2-7                       [32, 192, 13, 13]         [32, 384, 13, 13]         False\n","│    └─ReLU: 2-8                         [32, 384, 13, 13]         [32, 384, 13, 13]         --\n","│    └─Conv2d: 2-9                       [32, 384, 13, 13]         [32, 256, 13, 13]         False\n","│    └─ReLU: 2-10                        [32, 256, 13, 13]         [32, 256, 13, 13]         --\n","│    └─Conv2d: 2-11                      [32, 256, 13, 13]         [32, 256, 13, 13]         False\n","│    └─ReLU: 2-12                        [32, 256, 13, 13]         [32, 256, 13, 13]         --\n","│    └─MaxPool2d: 2-13                   [32, 256, 13, 13]         [32, 256, 6, 6]           --\n","├─AdaptiveAvgPool2d: 1-2                 [32, 256, 6, 6]           [32, 256, 6, 6]           --\n","├─Sequential: 1-3                        [32, 9216]                [32, 4]                   True\n","│    └─Dropout: 2-14                     [32, 9216]                [32, 9216]                --\n","│    └─Linear: 2-15                      [32, 9216]                [32, 4]                   True\n","===================================================================================================================\n","Total params: 2,506,564\n","Trainable params: 36,868\n","Non-trainable params: 2,469,696\n","Total mult-adds (G): 20.99\n","===================================================================================================================\n","Input size (MB): 19.27\n","Forward/backward pass size (MB): 124.16\n","Params size (MB): 10.03\n","Estimated Total Size (MB): 153.45\n","==================================================================================================================="]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["summary(model_0,input_size = [32,3,224,224],col_names=[\"input_size\",\"output_size\",\"trainable\"])"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:39:00.387739Z","iopub.status.busy":"2024-02-14T17:39:00.387071Z","iopub.status.idle":"2024-02-14T17:39:00.442407Z","shell.execute_reply":"2024-02-14T17:39:00.441491Z","shell.execute_reply.started":"2024-02-14T17:39:00.387694Z"},"trusted":true},"outputs":[{"data":{"text/plain":["===================================================================================================================\n","Layer (type:depth-idx)                   Input Shape               Output Shape              Trainable\n","===================================================================================================================\n","AlexNet                                  [32, 3, 224, 224]         [32, 4]                   Partial\n","├─Sequential: 1-1                        [32, 3, 224, 224]         [32, 256, 6, 6]           False\n","│    └─Conv2d: 2-1                       [32, 3, 224, 224]         [32, 64, 55, 55]          False\n","│    └─ReLU: 2-2                         [32, 64, 55, 55]          [32, 64, 55, 55]          --\n","│    └─MaxPool2d: 2-3                    [32, 64, 55, 55]          [32, 64, 27, 27]          --\n","│    └─Conv2d: 2-4                       [32, 64, 27, 27]          [32, 192, 27, 27]         False\n","│    └─ReLU: 2-5                         [32, 192, 27, 27]         [32, 192, 27, 27]         --\n","│    └─MaxPool2d: 2-6                    [32, 192, 27, 27]         [32, 192, 13, 13]         --\n","│    └─Conv2d: 2-7                       [32, 192, 13, 13]         [32, 384, 13, 13]         False\n","│    └─ReLU: 2-8                         [32, 384, 13, 13]         [32, 384, 13, 13]         --\n","│    └─Conv2d: 2-9                       [32, 384, 13, 13]         [32, 256, 13, 13]         False\n","│    └─ReLU: 2-10                        [32, 256, 13, 13]         [32, 256, 13, 13]         --\n","│    └─Conv2d: 2-11                      [32, 256, 13, 13]         [32, 256, 13, 13]         False\n","│    └─ReLU: 2-12                        [32, 256, 13, 13]         [32, 256, 13, 13]         --\n","│    └─MaxPool2d: 2-13                   [32, 256, 13, 13]         [32, 256, 6, 6]           --\n","├─AdaptiveAvgPool2d: 1-2                 [32, 256, 6, 6]           [32, 256, 6, 6]           --\n","├─Sequential: 1-3                        [32, 9216]                [32, 4]                   True\n","│    └─Dropout: 2-14                     [32, 9216]                [32, 9216]                --\n","│    └─Linear: 2-15                      [32, 9216]                [32, 4]                   True\n","===================================================================================================================\n","Total params: 2,506,564\n","Trainable params: 36,868\n","Non-trainable params: 2,469,696\n","Total mult-adds (G): 20.99\n","===================================================================================================================\n","Input size (MB): 19.27\n","Forward/backward pass size (MB): 124.16\n","Params size (MB): 10.03\n","Estimated Total Size (MB): 153.45\n","==================================================================================================================="]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["# Freeze all base layers in the \"features\" section of the model (the feature extractor) by setting requires_grad=False\n","for param in model_0.features.parameters():\n","    param.requires_grad = False\n","# Check summary again after\n","summary(model_0, input_size= [32,3,224,224],col_names= [\"input_size\",\"output_size\",\"trainable\"])"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:39:04.831884Z","iopub.status.busy":"2024-02-14T17:39:04.831506Z","iopub.status.idle":"2024-02-14T17:39:04.838985Z","shell.execute_reply":"2024-02-14T17:39:04.838152Z","shell.execute_reply.started":"2024-02-14T17:39:04.831854Z"},"trusted":true},"outputs":[],"source":["# Set the manual seeds\n","torch.manual_seed(42)\n","torch.cuda.manual_seed(42)\n","\n","# Get the length of class_names (one output unit for each class)\n","output_shape = len(class_names)\n","\n","# Recreate the classifier layer and seed it to the target device\n","model_0.classifier = torch.nn.Sequential(\n","    torch.nn.Dropout(p=0.2, inplace=True),\n","    torch.nn.Linear(in_features=9216,\n","                    out_features=output_shape, # same number of output units as our number of classes\n","                    bias=True)).to(device)"]},{"cell_type":"markdown","metadata":{},"source":["# Train Model"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:39:08.738005Z","iopub.status.busy":"2024-02-14T17:39:08.737623Z","iopub.status.idle":"2024-02-14T17:39:08.744221Z","shell.execute_reply":"2024-02-14T17:39:08.743179Z","shell.execute_reply.started":"2024-02-14T17:39:08.737977Z"},"trusted":true},"outputs":[],"source":["# Define loss and optimizer\n","loss_fn = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model_0.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:41:58.051274Z","iopub.status.busy":"2024-02-14T17:41:58.050296Z","iopub.status.idle":"2024-02-14T17:49:00.160771Z","shell.execute_reply":"2024-02-14T17:49:00.159769Z","shell.execute_reply.started":"2024-02-14T17:41:58.051232Z"},"trusted":true},"outputs":[],"source":["# Set the random seeds\n","torch.manual_seed(42)\n","torch.cuda.manual_seed(42)\n","\n","# Start the timer\n","from timeit import default_timer as timer\n","start_time = timer()\n","\n","# Setup training and save the results\n","model_0_results = train(model=model_0,\n","                       train_dataloader=train_dataloader,\n","                       test_dataloader=test_dataloader,\n","                       optimizer=optimizer,\n","                       loss_fn=loss_fn,\n","                       epochs=50,\n","                       device=device)\n","\n","# End the timer and print out how long it took\n","end_time = timer()\n","#print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")"]},{"cell_type":"markdown","metadata":{},"source":["[INFO] Total training time: 422.101 seconds for 50 epochs.\n","Final test accuracy = 0.5197\n","Loss plateaued at a point"]},{"cell_type":"markdown","metadata":{},"source":["Make predictions on the entire test dataset with the model"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:40:37.585072Z","iopub.status.busy":"2024-02-14T17:40:37.584212Z","iopub.status.idle":"2024-02-14T17:40:37.591445Z","shell.execute_reply":"2024-02-14T17:40:37.590547Z","shell.execute_reply.started":"2024-02-14T17:40:37.585035Z"},"trusted":true},"outputs":[{"data":{"text/plain":["9"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["len(test_dataloader)"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:52:34.361696Z","iopub.status.busy":"2024-02-14T17:52:34.361296Z","iopub.status.idle":"2024-02-14T17:52:37.177102Z","shell.execute_reply":"2024-02-14T17:52:37.175897Z","shell.execute_reply.started":"2024-02-14T17:52:34.361661Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3ce2d524d09c4bb09cf0307fc0c39713","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/9 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from tqdm.auto import tqdm\n","model_0.eval()\n","test_preds = []\n","with torch.inference_mode():\n","    for X,y in tqdm(test_dataloader):\n","        # move data to device\n","        X, y = X.to(device), y.to(device)\n","        # pass the data to the model\n","        test_logits = model_0(X)\n","        # get the probs using softmax\n","        pred_probs = torch.softmax(test_logits,dim=1)\n","        # get the class labels\n","        pred_probs_labels = torch.argmax(pred_probs,dim=1)\n","        # store in test_preds list\n","        test_preds.append(pred_probs_labels)\n","\n","# concatenate to a tensor and take to cpu for further analysis\n","test_preds = torch.cat(test_preds).cpu()"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:52:41.498377Z","iopub.status.busy":"2024-02-14T17:52:41.497506Z","iopub.status.idle":"2024-02-14T17:52:41.507846Z","shell.execute_reply":"2024-02-14T17:52:41.506777Z","shell.execute_reply.started":"2024-02-14T17:52:41.498336Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([2, 2, 2, 3, 0, 0, 1, 2, 2, 0, 2, 0, 0, 0, 0, 3, 2, 1, 0, 2, 0, 0, 3, 3,\n","        2, 3, 2, 0, 0, 0, 1, 2, 3, 0, 1, 0, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 1, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 1, 1, 1, 0,\n","        3, 1, 1, 0, 1, 2, 1, 3, 0, 2, 2, 2, 3, 2, 1, 3, 1, 1, 3, 2, 1, 1, 2, 1,\n","        2, 3, 1, 2, 1, 3, 2, 3, 3, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 2, 2, 3, 1,\n","        3, 3, 1, 3, 0, 2, 0, 0, 1, 2, 2, 2, 2, 2, 3, 2, 2, 1, 2, 1, 2, 2, 3, 2,\n","        2, 1, 0, 2, 2, 2, 3, 2, 2, 0, 1, 2, 2, 2, 2, 3, 2, 1, 1, 2, 2, 2, 2, 2,\n","        1, 2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 3, 2, 2, 1, 2, 3, 3, 3, 2, 3,\n","        3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 0, 2, 0, 2, 1, 3, 3, 2, 1,\n","        0, 3, 3, 2, 3, 2, 1, 3, 3, 1, 3, 3, 2, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 0,\n","        3, 3, 1, 3, 3, 2, 3, 3, 2, 3, 0, 3, 3, 3, 2, 2, 3, 1, 2, 2, 1, 3, 2, 1,\n","        3, 2, 3, 2, 3, 1, 3, 0, 2, 3, 3, 2, 3, 3, 3, 1])"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["test_preds"]},{"cell_type":"markdown","metadata":{},"source":["Make a confusion matrix with the test preds and the truth labels\n"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:52:44.835708Z","iopub.status.busy":"2024-02-14T17:52:44.834904Z","iopub.status.idle":"2024-02-14T17:52:46.382120Z","shell.execute_reply":"2024-02-14T17:52:46.381001Z","shell.execute_reply.started":"2024-02-14T17:52:44.835677Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0]),\n"," tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0]),\n"," tensor([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1]),\n"," tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1]),\n"," tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","         2, 2, 2, 2, 2, 2, 2, 2]),\n"," tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","         2, 2, 2, 2, 2, 2, 2, 2]),\n"," tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n","         3, 3, 3, 3, 3, 3, 3, 3]),\n"," tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n","         3, 3, 3, 3, 3, 3, 3, 3]),\n"," tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])]"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["y_test_true = [y for X,y in test_dataloader]\n","y_test_true"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:52:57.393221Z","iopub.status.busy":"2024-02-14T17:52:57.392835Z","iopub.status.idle":"2024-02-14T17:52:57.403362Z","shell.execute_reply":"2024-02-14T17:52:57.402550Z","shell.execute_reply.started":"2024-02-14T17:52:57.393187Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n","        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n","        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n","        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n","        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["# Need to concatenate them\n","y_test_true = torch.cat(y_test_true)\n","y_test_true"]},{"cell_type":"markdown","metadata":{},"source":["Need the following libraries to make a confusion matrix:\n","\n","torchmetrics - https://torchmetrics.readthedocs.io/en/stable/\n","mlxtend - http://rasbt.github.io/mlxtend/"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:53:14.502402Z","iopub.status.busy":"2024-02-14T17:53:14.501758Z","iopub.status.idle":"2024-02-14T17:53:37.410447Z","shell.execute_reply":"2024-02-14T17:53:37.409473Z","shell.execute_reply.started":"2024-02-14T17:53:14.502369Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["mlxtend version: 0.23.1\n"]}],"source":["# See if torchmetrics exists, if not, install it\n","try:\n","    import torchmetrics, mlxtend\n","    print(f\"mlxtend version: {mlxtend.__version__}\")\n","    assert int(mlxtend.__version__.split(\".\")[1]) >= 19, \"mlxtend verison should be 0.19.0 or higher\"\n","except:\n","    !pip install -q torchmetrics -U mlxtend # <- Note: If you're using Google Colab, this may require restarting the runtime\n","    import torchmetrics, mlxtend\n","    print(f\"mlxtend version: {mlxtend.__version__}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-02-14T17:20:23.099254Z","iopub.status.idle":"2024-02-14T17:20:23.099576Z","shell.execute_reply":"2024-02-14T17:20:23.099433Z","shell.execute_reply.started":"2024-02-14T17:20:23.099419Z"},"trusted":true},"outputs":[],"source":["# Import mlxtend upgraded version\n","import mlxtend\n","print(mlxtend.__version__)"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:53:42.945951Z","iopub.status.busy":"2024-02-14T17:53:42.945219Z","iopub.status.idle":"2024-02-14T17:54:09.656653Z","shell.execute_reply":"2024-02-14T17:54:09.655682Z","shell.execute_reply.started":"2024-02-14T17:53:42.945913Z"},"trusted":true},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAokAAAKBCAYAAAA7hDFMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABZXklEQVR4nO3dd1xV9ePH8fcFBBQB98a9c2sq7lJzlVKmZu5cpThyZqY5Ks2RI8sc5SjTzLSvZZYjNVduUZPU3APFkQxRVPj8/vDnrfs9atIXOQiv5+PBo868b66Xy5tzzudchzHGCAAAAPgbN7sDAAAAIPmhJAIAAMCCkggAAAALSiIAAAAsKIkAAACwoCQCAADAgpIIAAAACw+7A8BVfHy8zp07J19fXzkcDrvjAACAFMYYo6ioKOXKlUtubvc/XkhJTGbOnTungIAAu2MAAIAU7vTp08qTJ899l1MSkxlfX19JUv7u8+Xmmc7mNEhOVvSvZXcEJFOrj16wOwKSqUZFc9odAclQVFSUKpQs4Owc90NJTGbunmJ280wnNy9KIv7i6+dndwQkU2l9YuyOgGSK9w08yD9d1sbAFQAAAFhQEgEAAGBBSQQAAIAFJREAAAAWlEQAAABYUBIBAABgQUkEAACABSURAAAAFpREAAAAWFASAQAAYEFJBAAAgAUlEQAAABaURAAAAFhQEgEAAGBBSQQAAIAFJREAAAAWlEQAAABYUBIBAABgQUkEAACABSURAAAAFpREAAAAWFASAQAAYEFJBAAAgAUlEQAAABaURAAAAFhQEgEAAGBBSQQAAIAFJREAAAAWlEQAAABYUBIBAABgQUkEAACABSURAAAAFpREAAAAWFASAQAAYEFJBAAAgAUlEQAAABaURAAAAFhQEgEAAGBBSQQAAIAFJREAAAAWlEQAAABYUBIBAABgQUkEAACABSURAAAAFpREAAAAWFASAQAAYEFJBAAAgAUlEQAAABaURAAAAFhQEgEAAGBBSQQAAIAFJREAAAAWlEQAAABYUBIBAABgQUkEAACABSURAAAAFpREAAAAWFASAQAAYEFJBAAAgIWH3QGQur0cmFetAwOUJ2M6SdKRC1GatvoP/XLokiTpi1crq0qhzC7bLNx6SsOX/pbkWWGvuLg4fTB2tJZ+vVDh4ReUI0dOtWjdTn0GDJHD4bA7HpLQD/M+0u71P+n8yaPy9PJWodIV1LznG8qRr5BznVuxN7R46rvasfo73b51U09UqaU2A0fLL3NWG5MjqVUqXURnTp20zO/Y5VWNnTjVhkSPl8fuSGKdOnXUt2/f/2kfv//+u6pWrSpvb2+VK1fuvvP+yYgRIx56Xdzb+as3NOGHwwqaslnPT9msrX9c1vSOFVU4e3rnOot+PaXAUWudX+NWHLIxMezy8ZQJmj9nlt4ZN1nrf92rIW+/q+kffqDPZn5sdzQkscN7tump5u00ZPYyvT71c8Xdvq1Jfdor9nqMc52vJo/Wvk1r1f29jzVw+le6eumCPn7jVRtTww4/rtuifYdPOb8Wf7tSkvRcUHObkz0eUuWRxLfffls+Pj46dOiQ0qdPf995ePR+Dg13mZ704xG9HJhX5fJm0B8XoiVJN27F61LUTTviIRnZuf1XPdPoWdV9ppEkKSBvfv3nm8Xau3uHzcmQ1PpOnu8y3WnYBPVrVFEnf9+vouWrKCY6Upu+W6yuo6aoRKVqkqSOb43X8Jfq6eiB3SpUqoIdsWGDLFlcjxx/OGm88hcopGo1atmU6PHy2B1JTAxHjx5VjRo1lC9fPmXOnPm+85C03BxSk7I5lc7TQ3tPXnXOb1o+l7aNqKsV/Wuof6Oi8k6TKl+2qV6lylW1+Zd1OvbHEUnSwQP7tGPbFj1Vr4HNyWC369FRkiQfvwySpJO/H1Dc7Vsq8WR15zo58xdWphy5dWz/bjsiIhm4efOmvvnqS7Vu24FLVB7SY/nb9vbt2woODpa/v7+yZMmiYcOGyRgjSXI4HPr2229d1s+QIYPmzp3rXL5r1y6NGjVKDodDI0aMuOc8SRo8eLCKFi2qdOnSqWDBgho2bJhu3bp131zx8fEaNWqU8uTJIy8vL5UrV04//vjjo3gKUpSiOdJr7zv19duYBhrV/An1mLdbf4TfOYr43Z4w9V8YonafbNOMn48pqEJuTWxd1ubEsEPPvgPV9IWWql2ljPJnS68Gtauoy6vBeqFFa7ujwUbx8fFaNHmUCpeppNyFikmSIi9flEcaT6Xz9XdZ1y9TFkVcvmhHTCQDK7//jyIirqpVm/Z2R3lsPJanm+fNm6fOnTtr+/bt2rlzp7p166a8efOqa9eu/7htWFiY6tWrp4YNG2rAgAFKnz69Xn31Vcs8SfL19dXcuXOVK1cu7d+/X127dpWvr68GDRp0z31PmTJFEydO1IwZM1S+fHl99tlnatq0qX777TcVKVLkntvExsYqNjbWOR0ZGfkvnpHH2/GL19R00mb5enuoYZkcGteqjNpM36Y/wqP11bbTzvUOn49WeOQNff5qFeXNnE6nLsc8YK9Iab5btkTLvl6oaTPnqWiJkvptf4hGvDlQ2f9/AAtSpy/HD9O5o4c0aOYSu6MgmVv4+Vw9Xb+BcuTMZXeUx8ZjeSQxICBAkyZNUrFixdSmTRv16tVLkyZNeqhtc+TIIQ8PD6VPn145cuRw/ve/50nSW2+9pWrVqil//vx67rnnNGDAAC1evPi++54wYYIGDx6sl156ScWKFdP777+vcuXKafLkyffdZsyYMfL393d+BQQEJOi5SAluxRmduhyj385GauLKwwoNi1SHmvnuuW7IqQhJUt7M6ZIyIpKBd94eop59B6pZ85YqUbKUXmzVRl1f66Vpk8fbHQ02+XLCcO3b/LP6f7xImbLldM73y5xVt2/dVExUhMv6kVcuyZ/RzanS6VMn9cv6tWrT/hW7ozxWHsuSWLVqVZfrCQIDA3XkyBHFxcUl6uN89dVXql69urM4vvXWWzp16tQ9142MjNS5c+dUvXp1l/nVq1dXaGjofR9jyJAhioiIcH6dPn36vuumFm4Ohzw97v3SLJHbV5J0MSr2nsuRcl2/fl1ubq6vC3d3d8XHx9uUCHYxxujLCcO1Z8NP6j/tS2XN5frHdb7ipeTukUahO7Y4550/eVRXzp9VwdIMWkmNFi2YpyxZs6leg8Z2R3msPJanmx/E4XA4r0+860HXEd7P1q1b1aZNG40cOVINGjSQv7+/Fi1apIkTJyZWVEmSl5eXvLy8EnWfj5P+jYrql98v6tzVG/Lxctdz5XOpSsFMemX2DuXNnE7Plc+p9aEXdTXmlorl9NXQpiW0/egVHQqLsjs6klj9ho01deL7yp0nQEWLl9CBfSGa+fFUtWrTwe5oSGJfjh+mbav+o57jZsnbx0cRl+/cJSGtj588vb2VLr2fajzXUounviMff3+l9fHVwolvq1DpCoxsToXi4+O1aMF8tWzdVh4eKa72PFKP5bO1bds2l+lff/1VRYoUkbu7u7JmzaqwsDDnsiNHjigmJuHXrm3ZskX58uXT0KFDnfNOnrTekPMuPz8/5cqVS5s3b1bt2rWd8zdv3qzKlSsn+PFTi8zpPTXupTLK5uetqBu39HtYlF6ZvUObj1xWDn9vVSucRR1q5Fc6T3eFXb2hn/af18drjtodGzYYPXaSxr83Um8O6K1Lly4qR46catuxs/oOHPrPGyNFWb/0C0nShB4vuczv+NZ4VX+2hSSpVd9hcri5afqQ13T75v/fTHvQ6CTPCvv9sm6tzp4+pdbtOtod5bHzWJbEU6dOqV+/furevbt2796tDz/80HmE7+mnn9a0adMUGBiouLg4DR48WGnSpEnwYxQpUkSnTp3SokWL9OSTT2rFihVatmzZA7cZOHCg3n77bRUqVEjlypXTnDlztHfvXi1YsOBffZ+pwZtfH7jvsvMRN9Tmk233XY7UJb2vr0aOmaCRYybYHQU2m/XriX9cJ42Xt9oMHK02AymGqV2duvV1PoJ77f4bj2VJbN++va5fv67KlSvL3d1dffr0Ubdu3SRJEydOVKdOnVSzZk3lypVLU6ZM0a5duxL8GE2bNtXrr7+u4OBgxcbGqkmTJho2bJjz9jj30rt3b0VERKh///4KDw9XyZIltXz58vuObAYAAEiuHOa/L+CDrSIjI+Xv76+CvZbIzYsRvPjL+jeftjsCkqmVh8/bHQHJ1HMluN0LrKIiI1UkIIsiIiLk5+d33/Uey9HNAAAAeLQoiQAAALCgJAIAAMCCkggAAAALSiIAAAAsKIkAAACwoCQCAADAgpIIAAAAC0oiAAAALCiJAAAAsKAkAgAAwIKSCAAAAAtKIgAAACwoiQAAALCgJAIAAMCCkggAAAALSiIAAAAsKIkAAACwoCQCAADAgpIIAAAAC0oiAAAALCiJAAAAsKAkAgAAwIKSCAAAAAtKIgAAACwoiQAAALCgJAIAAMCCkggAAAALSiIAAAAsKIkAAACwoCQCAADAgpIIAAAAC0oiAAAALCiJAAAAsKAkAgAAwIKSCAAAAAtKIgAAACwoiQAAALCgJAIAAMCCkggAAAALSiIAAAAsKIkAAACwoCQCAADAgpIIAAAAC0oiAAAALCiJAAAAsKAkAgAAwIKSCAAAAAtKIgAAACwoiQAAALCgJAIAAMCCkggAAAALSiIAAAAsKIkAAACwoCQCAADAgpIIAAAAC0oiAAAALCiJAAAAsKAkAgAAwMLD7gC4t58G1ZGvn5/dMZCM9Fv+m90RkEyVye1rdwQkUycuXrM7ApKha1EP97rgSCIAAAAsKIkAAACwoCQCAADAgpIIAAAAC0oiAAAALCiJAAAAsKAkAgAAwIKSCAAAAAtKIgAAACwoiQAAALCgJAIAAMCCkggAAAALSiIAAAAsKIkAAACwoCQCAADAgpIIAAAAC0oiAAAALCiJAAAAsKAkAgAAwIKSCAAAAAtKIgAAACwoiQAAALCgJAIAAMCCkggAAAALSiIAAAAsKIkAAACwoCQCAADAgpIIAAAAC0oiAAAALCiJAAAAsKAkAgAAwIKSCAAAAAtKIgAAACwoiQAAALCgJAIAAMCCkggAAAALSiIAAAAsKIkAAACwoCQCAADAgpIIAAAAC0oiAAAALCiJAAAAsKAkAgAAwIKSCAAAAAtKIgAAACwoiQAAALCgJAIAAMCCkggAAAALSiIAAAAsKIkAAACwoCQCAADAgpIIAAAAC0oiAAAALCiJAAAAsKAkAgAAwIKSCAAAAAtKIgAAACwoiQAAALCgJAIAAMCCkggAAAALSiIAAAAsKIkAAACw8LA7APDfKpUuojOnTlrmd+zyqsZOnGpDItih6RPZVClvBuXy89LNuHgduRijRXvOKSwyVpKUxcdTU54vec9tp/xyXNtPRSRlXCShdV9O128bVyn81DGl8fJSvicqqFHXQcqat6AkKSbyqlbPnaIjOzfpavg5+WTIpCeq19cznV6Xd3pfm9PjUdqzfbO+mPWhDv0Wokvh5/X+9C9Uu36Te677/rDXtWzhXPUd+p5e6vRaEid9PCTbkrh+/Xo99dRT+vPPP5UhQ4ZE26/D4dCyZcsUFBSUaPtE4vpx3RbFx8U5p38/+JtaBjXSc0HNbUyFpFY8e3qtOXRJRy/HyN0htSyfU288XUiDvvtdsXHxuhxzUz2WHHDZ5ukimdWkZDaFnIuyKTWSwvGQ7ararK0CipVWXHycfpo9UZ8O6qh+c36UZ9p0irwcrsjL4Wr86hvKnq+w/rxwTt9OHqbIyxfUdsRHdsfHI3T9eoyKlCil51q01Rs92t13vfWrvteBvTuVNXvOJEz3+Em2JfFxlz9/fvXt21d9+/a1O8pjJ0uWrC7TH04ar/wFCqlajVo2JYIdxv18zGV6xpZT+qRFaRXInFa/h1+TMVLEjdsu61QK8Ne2k1cVezs+KaMiib3y/hyX6RaD39c7L1TRmcMHVLBsZeUoUFTtRv5VBjPnzqdnXumnr8b0V1zcbbm786svpapWu76q1a7/wHXCz5/TxJGDNWXOEvXr2iqJkj2euCYRydrNmzf1zVdfqnXbDnI4HHbHgY3SpXGXJEXHxt1zef5MaZU/Uzqt/+NyUsZCMnDj2p0jx+n8MjxwHe906SmIqVx8fLxGDnhVbbv2UsGiJeyOk+zZWhLj4+M1ZswYFShQQGnTplXZsmW1ZMmS+66/adMm1axZU2nTplVAQIB69+6ta9euOZfnz59fo0ePVuvWreXj46PcuXPro4+spxYuXbqk559/XunSpVORIkW0fPly57K4uDh17tzZmalYsWKaMmWKy/YdO3ZUUFCQJkyYoJw5cypz5szq2bOnbt26JUmqU6eOTp48qddff10Oh4Ny8z9Y+f1/FBFxVa3atLc7CmzkkNSuUm4dCo/WmYgb91ynTqHMOnv1ho5ciknacLBVfHy8vv/oXeUrVVE5ChS95zrXIq7o588/UuVnX0ridEhuPp8xWe7uHmrZobvdUR4LtpbEMWPGaP78+frkk0/022+/6fXXX1fbtm21YcMGy7pHjx5Vw4YN1bx5c+3bt09fffWVNm3apODgYJf1xo8fr7Jly2rPnj1644031KdPH61evdplnZEjR6ply5bat2+fGjdurDZt2ujKlSuS7rzh5MmTR19//bUOHjyo4cOH680339TixYtd9rFu3TodPXpU69at07x58zR37lzNnTtXkrR06VLlyZNHo0aNUlhYmMLCwu77HMTGxioyMtLlC39Z+PlcPV2/gXLkzGV3FNioY+U8ypMhraZtsg5okqQ07g5VK5BR649yFDG1+c+UETp//LBeHjb5nstvXIvS3CFdlS1/YdXr0DtpwyFZ+f3AXn01b4aGjfuIgzcPyWGMMXY8cGxsrDJlyqQ1a9YoMDDQOb9Lly6KiYlRt27dXAaudOnSRe7u7poxY4Zz3U2bNql27dq6du2avL29lT9/fpUoUUIrV650rvPSSy8pMjJSP/zwg6Q7A1feeustjR49WpJ07do1pU+fXitXrlTDhg3vmTU4OFjnz593HuXs2LGj1q9fr6NHj8rd/c4psJYtW8rNzU2LFi2S9PDXJI4YMUIjR460zD9y+pJ8/fz+6WlM0U6fOqkqZYvpsy8Wq2GTpnbHsV2/5b/ZHcEWHZ7MrYp5/DV61R+6eO3mPdepUSCjulYNUPDS3xR1n9PRKVmZ3KlzxO5/pozQwS1r1H3yQmXKGWBZHhsTrU8HdZKnd1p1eG+W0nh62ZDSXnXyZrY7gm2qFs7oMrp50ZzpmvLeULm5/XV8LC4uTm5ubsqWM7e+3bDPrqhJ7lpUpOqWz6eIiAj5PaBr2HZxxh9//KGYmBjVr+96genNmzdVvnx5y/ohISHat2+fFixY4JxnjFF8fLyOHz+uEiXuXFvw98J5d3ry5Mku88qUKeP8fx8fH/n5+Sk8PNw576OPPtJnn32mU6dO6fr167p586bKlSvnso8nnnjCWRAlKWfOnNq/f//DffN/M2TIEPXr1885HRkZqYAA65tdarRowTxlyZpN9Ro0tjsKbNLhydyqFOCvd1bfvyBKUu3CmbX7TGSqLIipkTFGy6eO1G+bVqvbpAX3LIg3rkXps8Gd5J7GU+3fmZEqCyJcNQpqpSer13aZ17fTi2rYrKWefbGNTamSN9tKYnR0tCRpxYoVyp07t8syLy8vHT161LJ+9+7d1bu39XRB3rx5E/TYadKkcZl2OByKj78zGnLRokUaMGCAJk6cqMDAQPn6+mr8+PHatm3bQ+8jIby8vOTlxZvXf4uPj9eiBfPVsnVbeXhwoXlq1PHJPKpWIKM+WH9MN27Fy9/7zusg5lacbsX9dQIke3pPFc/mo/H/NRoaKdd/prytvWu/U/t3PpFXOh9FXbkoSfL28VUaL2/duBalTwd11K3YG2o3ZKJiY6IVG3Pnd46Pfya5/e0PfKQsMdeidebkcef0udMndfjgfvllyKAcuQLknzGTy/ruHh7KnDW78hUsktRRHwu2/fYtWbKkvLy8dOrUKdWuXduy/L9LYoUKFXTw4EEVLlz4gfv99ddfLdN3jzI+jM2bN6tatWrq0aPHfbM8DE9PT8XFcVTj3/pl3VqdPX1Krdt1tDsKbFK/WBZJ0rBnXN+8Z2w5pV+OXXFO1y6cWVdibml/GPdGTC1+Xf6lJGnm665Hf14c9L4qNWyus0d+0+nQEEnS+HZ1XdYZ9OV6ZcqRJ2mCIsmF7t+rnm2fc05PeW+oJKnxC601fNzHdsV6bNlWEn19fTVgwAC9/vrrio+PV40aNRQREaHNmzfLz89P+fLlc1l/8ODBqlq1qoKDg9WlSxf5+Pjo4MGDWr16taZNm+Zcb/PmzRo3bpyCgoK0evVqff3111qxYsVD5ypSpIjmz5+vn376SQUKFNDnn3+uHTt2qECBAgn6/vLnz69ffvlFL730kry8vJQlS5YEbZ/a1albX+cj7n96ESlfmy/2PtR6i/eGafHe+w8OQ8oz9uc/Hri8ULmq/7gOUqaKVWvo1z/+fOj1U9N1iP+GrefxRo8eraxZs2rMmDE6duyYMmTIoAoVKujNN9+0nLotU6aMNmzYoKFDh6pmzZoyxqhQoUJq1cr1Rpj9+/fXzp07NXLkSPn5+emDDz5QgwYNHjpT9+7dtWfPHrVq1UoOh0OtW7dWjx49XAbDPIxRo0ape/fuKlSokGJjY2XT+CAAAIB/xbbRzY9CSviUk8jISPn7+zO6GRapdXQz/llqHd2Mf5aaRzfj/h52dDOfuAIAAAALSiIAAAAsUtS9RU6cOGF3BAAAgBSBI4kAAACwoCQCAADAgpIIAAAAC0oiAAAALCiJAAAAsKAkAgAAwIKSCAAAAAtKIgAAACwoiQAAALCgJAIAAMCCkggAAAALSiIAAAAsKIkAAACwoCQCAADAgpIIAAAAC0oiAAAALCiJAAAAsKAkAgAAwIKSCAAAAAtKIgAAACwoiQAAALCgJAIAAMCCkggAAAALSiIAAAAsKIkAAACwoCQCAADAwuNhVlq+fPlD77Bp06b/OgwAAACSh4cqiUFBQQ+1M4fDobi4uP8lDwAAAJKBhyqJ8fHxjzoHAAAAkpH/6ZrEGzduJFYOAAAAJCMJLolxcXEaPXq0cufOrfTp0+vYsWOSpGHDhunTTz9N9IAAAABIegkuie+++67mzp2rcePGydPT0zm/VKlSmj17dqKGAwAAgD0SXBLnz5+vmTNnqk2bNnJ3d3fOL1u2rH7//fdEDQcAAAB7JLgknj17VoULF7bMj4+P161btxIlFAAAAOyV4JJYsmRJbdy40TJ/yZIlKl++fKKEAgAAgL0e6hY4fzd8+HB16NBBZ8+eVXx8vJYuXapDhw5p/vz5+v777x9FRgAAACSxBB9JbNasmb777jutWbNGPj4+Gj58uEJDQ/Xdd9+pfv36jyIjAAAAkliCjyRKUs2aNbV69erEzgIAAIBk4l+VREnauXOnQkNDJd25TrFixYqJFgoAAAD2SnBJPHPmjFq3bq3NmzcrQ4YMkqSrV6+qWrVqWrRokfLkyZPYGQEAAJDEEnxNYpcuXXTr1i2FhobqypUrunLlikJDQxUfH68uXbo8iowAAABIYgk+krhhwwZt2bJFxYoVc84rVqyYPvzwQ9WsWTNRwwEAAMAeCT6SGBAQcM+bZsfFxSlXrlyJEgoAAAD2SnBJHD9+vHr16qWdO3c65+3cuVN9+vTRhAkTEjUcAAAA7PFQp5szZswoh8PhnL527ZqqVKkiD487m9++fVseHh565ZVXFBQU9EiCAgAAIOk8VEmcPHnyI44BAACA5OShSmKHDh0edQ4AAAAkI//6ZtqSdOPGDd28edNlnp+f3/8UCAAAAPZL8MCVa9euKTg4WNmyZZOPj48yZszo8gUAAIDHX4JL4qBBg/Tzzz9r+vTp8vLy0uzZszVy5EjlypVL8+fPfxQZAQAAkMQSfLr5u+++0/z581WnTh116tRJNWvWVOHChZUvXz4tWLBAbdq0eRQ5AQAAkIQSfCTxypUrKliwoKQ71x9euXJFklSjRg398ssviZsOAAAAtkhwSSxYsKCOHz8uSSpevLgWL14s6c4RxgwZMiRqOAAAANgjwSWxU6dOCgkJkSS98cYb+uijj+Tt7a3XX39dAwcOTPSAAAAASHoJvibx9ddfd/5/vXr19Pvvv2vXrl0qXLiwypQpk6jhAAAAYI//6T6JkpQvXz7ly5cvMbIAAAAgmXiokjh16tSH3mHv3r3/dRj8xS9dGvmlS2N3DCQjI+oXtTsCkqkyDQfZHQHJ1L4fx9kdAcmQp/F8qPUeqiROmjTpoXbmcDgoiQAAACnAQ5XEu6OZAQAAkDokeHQzAAAAUj5KIgAAACwoiQAAALCgJAIAAMCCkggAAACLf1USN27cqLZt2yowMFBnz56VJH3++efatGlTooYDAACAPRJcEr/55hs1aNBAadOm1Z49exQbGytJioiI0HvvvZfoAQEAAJD0ElwS33nnHX3yySeaNWuW0qT56xNBqlevrt27dydqOAAAANgjwSXx0KFDqlWrlmW+v7+/rl69mhiZAAAAYLMEl8QcOXLojz/+sMzftGmTChYsmCihAAAAYK8El8SuXbuqT58+2rZtmxwOh86dO6cFCxZowIABeu211x5FRgAAACSxh/rs5r974403FB8fr7p16yomJka1atWSl5eXBgwYoF69ej2KjAAAAEhiCS6JDodDQ4cO1cCBA/XHH38oOjpaJUuWVPr06R9FPgAAANggwSXxLk9PT5UsWTIxswAAACCZSHBJfOqpp+RwOO67/Oeff/6fAgEAAMB+CS6J5cqVc5m+deuW9u7dqwMHDqhDhw6JlQsAAAA2SnBJnDRp0j3njxgxQtHR0f9zIAAAANjvX3128720bdtWn332WWLtDgAAADZKtJK4detWeXt7J9buAAAAYKMEn25+4YUXXKaNMQoLC9POnTs1bNiwRAsGAAAA+yS4JPr7+7tMu7m5qVixYho1apSeeeaZRAsGAAAA+ySoJMbFxalTp04qXbq0MmbM+KgyAQAAwGYJuibR3d1dzzzzjK5evfqI4gAAACA5SPDAlVKlSunYsWOPIgsAAACSiQSXxHfeeUcDBgzQ999/r7CwMEVGRrp8AQAA4PGX4IErjRs3liQ1bdrU5eP5jDFyOByKi4tLvHQAAACwRYJL4rp16x5FDgAAACQjCS6JBQoUUEBAgMtRROnOkcTTp08nWjAAAADYJ8HXJBYoUEAXL160zL9y5YoKFCiQKKEAAABgrwSXxLvXHv636OhoPpYPAAAghXjo0839+vWTJDkcDg0bNkzp0qVzLouLi9O2bdtUrly5RA8IAACApPfQJXHPnj2S7hxJ3L9/vzw9PZ3LPD09VbZsWQ0YMCDxEwIAACDJPXRJvDuquVOnTpoyZYr8/PweWSgAAADYK8Gjm+fMmfMocgAAACAZSfDAFQAAAKR8lEQAAABYUBIBAABgQUkEAACABSURAAAAFpREAAAAWFASAQAAYEFJBAAAgAUlEQAAABaURAAAAFhQEgEAAGBBSQQAAIAFJREAAAAWlEQAAABYUBIBAABgQUkEAACABSURAAAAFpREAAAAWFASAQAAYEFJBAAAgAUlEQAAABaURAAAAFhQEgEAAGBBSQQAAIAFJREAAAAWlEQAAABYpMqSuH79ejkcDl29evW+64wYMULlypVLsky4t/HjxiptGocG9OtrdxTYYMfWTere7kXVKFtIRXP4aPXK71yWG2M05f3Rql6moErnz6wOLZroxLE/bEoLOwzoVF/X90zT+AHNXeZXKVNAK2f00qUtE3Vh43it/rSvvL3S2JQSSYX3jMSVKkviwxgwYIDWrl1rd4xUbeeOHfp01gyVLl3G7iiwSUzMNRV/orSGj5l0z+Wzpn2g+Z9O18hxU/X1D+uVLp2PXnmpmWJv3EjipLBDxZJ51bl5de07fMZlfpUyBfSfaT209tffVbPteNVoO16fLNqg+HhjU1IkFd4zEpeH3QHscPPmzX9cJ3369EqfPn0SpMG9REdHq1OHNvr4k1ka+947dseBTWrXbaDadRvcc5kxRvNmfaQefQepXsNnJUnjPpylwNIFtPrH7/RsUIukjIok5pPWU3Pe66geoxfqjS4NXZaN6/+CPl60XhPmrHbOO3IyPKkjwga8ZySuVHEksU6dOgoODlbfvn2VJUsWNWhw5wW0a9cuVapUSenSpVO1atV06NAh5zb/fbq5Y8eOCgoK0oQJE5QzZ05lzpxZPXv21K1bt5zr/Pnnn2rfvr0yZsyodOnSqVGjRjpy5EiSfZ8pSd9ePdWwURM9Xbee3VGQTJ0+dUIXwy8osNZTznm+fv4qW/5J7d25zcZkSAqTh7TSjxsPaN22Qy7zs2ZMr8plCujilWitm9tPJ9a8p1Wz+6hauYI2JUVywXtGwqWKkihJ8+bNk6enpzZv3qxPPvlEkjR06FBNnDhRO3fulIeHh1555ZUH7mPdunU6evSo1q1bp3nz5mnu3LmaO3euc3nHjh21c+dOLV++XFu3bpUxRo0bN3Ypkv8tNjZWkZGRLl+p3eKvFmnvnt0a/e4Yu6MgGbsUfkGSlCVrNpf5WbJm08VwjhqlZC0aVFS54gEa9uFyy7ICebJIkoZ2b6zPlm5Rs54fa2/oaf0wo5cK5c2a1FGRjPCekXCp5nRzkSJFNG7cOElSWFiYJOndd99V7dq1JUlvvPGGmjRpohs3bsjb2/ue+8iYMaOmTZsmd3d3FS9eXE2aNNHatWvVtWtXHTlyRMuXL9fmzZtVrVo1SdKCBQsUEBCgb7/9Vi1a3Psw9pgxYzRy5MjE/nYfW6dPn9bAfn30/crV9/13AJB65cmeQeMHNtezr01T7M3bluVubg5J0qffbNLny3+VJIUcOqM6lYupQ7NADb9HsQRwb6nmSGLFihUt88qU+WtARM6cOSVJ4Q/4a+KJJ56Qu7u7yzZ31w8NDZWHh4eqVKniXJ45c2YVK1ZMoaGh993nkCFDFBER4fw6ffr0w39TKdCe3bsUHh6uwMoVlN7bQ+m9PbTxlw36eNpUpff2UFxcnN0RkUxkyZZdknTpouvP7KWL4cqaLdu9NkEKUL5EXmXP7KetXw5W1I4pitoxRbUqFVGP1rUVtWOKLlyOkiSFHjvvst2h4+cVkCOjHZGRTPCekXCp5kiij4+PZV6aNH/dDsHhuPPXZ3x8/H338ff1727zoPUfhpeXl7y8vP6nfaQkTz1dVzv37HeZ161LJxUrVlz9Bw52KelI3QLy5lfWbNm1deN6lSxVVpIUHRWpkD071LpjF3vD4ZFZt/2QKr74rsu8mSPb6tDxC5o4d7WOn7mkc+FXVTS/6y/9wvmyadXmg0kZFckM7xkJl2pK4qNWokQJ3b59W9u2bXOebr58+bIOHTqkkiVL2pzu8eHr66snSpVymefj46NMmTNb5iPlu3YtWiePH3VOnzl1QgcPhChDhkzKlSdAHbr21PTJ45S/YGHlyZtPk98frWzZc6p+w+dsTI1HKTomVgePhrnMu3b9pq5EXHPOnzRvjd56tYn2Hz6rkENn1Pa5KiqWP7teHvipHZGRhHjPSFyUxERSpEgRNWvWTF27dtWMGTPk6+urN954Q7lz51azZs3sjgc8lg7s3a12zRs5p8e8/YYk6fmWbfT+1JnqGtxP12NiNGxAsCIjI1SxcqA+XfitvLieNVWb9uV6eXul0bj+zZXRP532Hz6rZ1+bpuNnLtkdDY8Y7xmJi5KYiObMmaM+ffro2Wef1c2bN1WrVi398MMPltPUSJhVa9fbHQE2qVK9lg6fv3bf5Q6HQ30GD1OfwcOSMBWSmwZdp1jmTZiz2uU+iUgdeM9IXA5jDLegT0YiIyPl7++vC5cj5OfnZ3ccJCOnL8fYHQHJVJmGg+yOgGRq34/j7I6AZCg6KlIViuRURMSDu0aqGd0MAACAh0dJBAAAgAUlEQAAABaURAAAAFhQEgEAAGBBSQQAAIAFJREAAAAWlEQAAABYUBIBAABgQUkEAACABSURAAAAFpREAAAAWFASAQAAYEFJBAAAgAUlEQAAABaURAAAAFhQEgEAAGBBSQQAAIAFJREAAAAWlEQAAABYUBIBAABgQUkEAACABSURAAAAFpREAAAAWFASAQAAYEFJBAAAgAUlEQAAABaURAAAAFhQEgEAAGBBSQQAAIAFJREAAAAWlEQAAABYUBIBAABgQUkEAACABSURAAAAFpREAAAAWFASAQAAYEFJBAAAgAUlEQAAABaURAAAAFhQEgEAAGBBSQQAAIAFJREAAAAWlEQAAABYUBIBAABgQUkEAACABSURAAAAFpREAAAAWFASAQAAYEFJBAAAgAUlEQAAABaURAAAAFhQEgEAAGBBSQQAAIAFJREAAAAWlEQAAABYUBIBAABgQUkEAACABSURAAAAFpREAAAAWHjYHQAA8L/5fM6bdkdAMlVtyHd2R0AyFH8z5qHW40giAAAALCiJAAAAsKAkAgAAwIKSCAAAAAtKIgAAACwoiQAAALCgJAIAAMCCkggAAAALSiIAAAAsKIkAAACwoCQCAADAgpIIAAAAC0oiAAAALCiJAAAAsKAkAgAAwIKSCAAAAAtKIgAAACwoiQAAALCgJAIAAMCCkggAAAALSiIAAAAsKIkAAACwoCQCAADAgpIIAAAAC0oiAAAALCiJAAAAsKAkAgAAwIKSCAAAAAtKIgAAACwoiQAAALCgJAIAAMCCkggAAAALSiIAAAAsKIkAAACwoCQCAADAgpIIAAAAC0oiAAAALCiJAAAAsKAkAgAAwIKSCAAAAAtKIgAAACwoiQAAALCgJAIAAMCCkggAAAALSiIAAAAsKIkAAACwoCQCAADAgpIIAAAAC0oiAAAALCiJAAAAsKAkAgAAwIKSCAAAAAtKIgAAACwoiQAAALCgJAIAAMCCkggAAAALSiIAAAAsKIkAAACwoCQCAADAgpIIAAAAC0oiAAAALCiJAAAAsKAk/pf8+fNr8uTJdsfA/xs/bqzSpnFoQL++dkeBDXZs3aTu7V5UjbKFVDSHj1av/M5luTFGU94freplCqp0/szq0KKJThz7w6a0SCoHd/2qsX06qFv9CmpRPre2r/vRZfn1mGuaPXaoujeoqJerFlLfF+po1dfzbUqLpNSxTiGtH9lAxz56Qcc+ekE/vFlXdUvncC7P5uetj7pU0W+TmurE9OZa+/YzerZiHhsTJ2+URCRbO3fs0KezZqh06TJ2R4FNYmKuqfgTpTV8zKR7Lp817QPN/3S6Ro6bqq9/WK906Xz0ykvNFHvjRhInRVKKvR6jfEVLqvOQd++5fN7Ekdq7Zb16v/uhJi9dryZtuujT99/SjvWrkjgpktq5P6/rnSX7VG/kKtUbtUqbfg/X/F41VCyXnyRpWpcqKpzDV22nblLt4T9qxa4zmv1aoErnzWBv8GSKkpgIbt26ZXeEFCc6OlqdOrTRx5/MUoaMGe2OA5vUrttAr7/xtp5p3NSyzBijebM+Uo++g1Sv4bMqXrK0xn04S+EXwrT6x+/usTekFOVrPK3WPQerytON7rn8cMhO1Xn2RT1RqZqy5QpQ/eZtla9oSf3x254kToqktirknNbsD9Ox8GgduxCt95bu17Ubt1WpUGZJUuXCmTV77RHtOX5FJy9e0wffH1REzC2VzZfJ5uTJU4oriSdOnJDD4bB81alTR5K0adMm1axZU2nTplVAQIB69+6ta9euuewjKipKrVu3lo+Pj3Lnzq2PPvrIZbnD4dD06dPVtGlT+fj46N1331VcXJw6d+6sAgUKKG3atCpWrJimTJmSVN92itO3V081bNRET9etZ3cUJFOnT53QxfALCqz1lHOer5+/ypZ/Unt3brMxGexWtGwl7dywWpfDw2SM0YEdmxV28pjKVq1tdzQkITeHQ0GVA5TOy0M7jl6WJG3/47KCKudVBh9PORxSUOUAeaVx1+ZD4TanTZ487A6Q2AICAhQWFuacPn/+vOrVq6datWrp6NGjatiwod555x199tlnunjxooKDgxUcHKw5c+Y4txk/frzefPNNjRw5Uj/99JP69OmjokWLqn79+s51RowYobFjx2ry5Mny8PBQfHy88uTJo6+//lqZM2fWli1b1K1bN+XMmVMtW7a8b97Y2FjFxsY6pyMjIxP5GXn8LP5qkfbu2a1Nv+6wOwqSsUvhFyRJWbJmc5mfJWs2XQznDT816zx4tGaMHqRXG1SSu4eHHA43vTpsnEpWrGp3NCSBErn9tXJoXXmlcde12NvqOG2zDp+787u1y/Qtmv1aoI58+Lxu3Y7X9Zu31XHaJh0Pj7Y5dfKU4kqiu7u7cuS4c5HqjRs3FBQUpMDAQI0YMULdunVTmzZt1LdvX0lSkSJFNHXqVNWuXVvTp0+Xt7e3JKl69ep64403JElFixbV5s2bNWnSJJeS+PLLL6tTp04ujz1y5Ejn/xcoUEBbt27V4sWLH1gSx4wZ47Jdanf69GkN7NdH369c7fz3AICEWLlojg7v363Bk+coa848Orh7m2aPHaqMWbOrTNVadsfDI/bH+Sg9NWKVfNOmUdNKefRhl8pq9v46HT4XqSHPl5ZfOk+9MH6drkTfVKPyuTX7tWp6bszPCj0bYXf0ZCfFnW7+u1deeUVRUVH68ssv5ebmppCQEM2dO1fp06d3fjVo0EDx8fE6fvy4c7vAwECX/QQGBio0NNRlXqVKlSyP99FHH6lixYrKmjWr0qdPr5kzZ+rUqVMPzDhkyBBFREQ4v06fPv0/fMePvz27dyk8PFyBlSsovbeH0nt7aOMvG/TxtKlK7+2huLg4uyMimciSLbsk6dJF16OGly6GK2u2bPfaBKlA7I3r+vLDserQ/21Vqv2M8hUtqUYvdVK1Z5pq+ecz7I6HJHArLl7Hw6O17+Sfeueb/frt9FV1q1dU+bP6qEu9Iurz2XZtDA3Xb6evasLy37T3xBW98nRhu2MnSynuSOJd77zzjn766Sdt375dvr6+ku4Mhujevbt69+5tWT9v3rwJ2r+Pj4/L9KJFizRgwABNnDhRgYGB8vX11fjx47Vt24OvjfLy8pKXl1eCHjsle+rputq5Z7/LvG5dOqlYseLqP3Cw3N3dbUqG5CYgb35lzZZdWzeuV8lSZSVJ0VGRCtmzQ607drE3HGwTd/u24m7fkpvD9RiIm7ubTHy8TalgJzeHQ14ebkrreafyxBvjsjw+3sjNzWFHtGQvRZbEb775RqNGjdLKlStVqFAh5/wKFSro4MGDKlz4wX8x/Prrr5bpEiVKPHCbzZs3q1q1aurRo4dz3tGjR/9F+tTN19dXT5Qq5TLPx8dHmTJntsxHynftWrROHv/r5+jMqRM6eCBEGTJkUq48AerQtaemTx6n/AULK0/efJr8/mhly55T9Rs+Z2NqPGrXY67p/Om/zv6Enz2l44cOKL1fRmXNmVslKwbq88nvyNPbW1ly5tHBXVu14ftv1KHfcBtTIym81by01u4/rzOXrym9dxo1r5pX1YtlU8sPNujI+UgduxClie0r6e3FIfozOlaNKuRR7ZI51GbKRrujJ0spriQeOHBA7du31+DBg/XEE0/o/PnzkiRPT08NHjxYVatWVXBwsLp06SIfHx8dPHhQq1ev1rRp05z72Lx5s8aNG6egoCCtXr1aX3/9tVasWPHAxy1SpIjmz5+vn376SQUKFNDnn3+uHTt2qECBAo/0+wVSsgN7d6td879uczLm7TvXCj/fso3enzpTXYP76XpMjIYNCFZkZIQqVg7Upwu/lRfXs6Zoxw6GaETXFs7peRPvXNdd+7kWCh41WX3HfqwvPxyjKW/2UnTkVWXNmVutew7SMy3a2xUZSSSLn7emdami7P7eirx+SwfPXFXLDzZow8E7A91aT/pFw14soy9615SPt4eOh0cr+NNtWrM/7B/2nDo5jPmv466Publz51oGlEhS7dq1tX79eu3YsUNDhw7V1q1bZYxRoUKF1KpVK7355puS7nziyiuvvKIDBw5oxYoV8vPz05AhQ1xOUTscDi1btkxBQUHOebGxsXr11Ve1bNkyORwOtW7dWv7+/lq5cqX27t370PkjIyPl7++vC5cj5Ofn96+fB6Q8py/H2B0ByVRI2FW7IyCZem0qR8hgFX8zRlcWvKKIiAd3jRRXEh93lETcDyUR90NJxP1QEnEvD1sSU/ToZgAAAPw7lEQAAABYUBIBAABgQUkEAACABSURAAAAFpREAAAAWFASAQAAYEFJBAAAgAUlEQAAABaURAAAAFhQEgEAAGBBSQQAAIAFJREAAAAWlEQAAABYUBIBAABgQUkEAACABSURAAAAFpREAAAAWFASAQAAYEFJBAAAgAUlEQAAABaURAAAAFhQEgEAAGBBSQQAAIAFJREAAAAWlEQAAABYUBIBAABgQUkEAACABSURAAAAFpREAAAAWFASAQAAYEFJBAAAgAUlEQAAABaURAAAAFhQEgEAAGBBSQQAAIAFJREAAAAWlEQAAABYUBIBAABgQUkEAACABSURAAAAFpREAAAAWFASAQAAYEFJBAAAgAUlEQAAABaURAAAAFhQEgEAAGBBSQQAAIAFJREAAAAWlEQAAABYUBIBAABgQUkEAACABSURAAAAFpREAAAAWFASAQAAYEFJBAAAgAUlEQAAABaURAAAAFhQEgEAAGDhYXcAuDLGSJKiIiNtToLkJjoqxu4ISKZioqPsjoBkKv4m7xuwMreu3/nv/3eO+6EkJjNRUXfe7AsXCLA5CQAASMmioqLk7+9/3+UO8081EkkqPj5e586dk6+vrxwOh91xbBUZGamAgACdPn1afn5+dsdBMsJrA/fDawP3wuvClTFGUVFRypUrl9zc7n/lIUcSkxk3NzflyZPH7hjJip+fHz/UuCdeG7gfXhu4F14Xf3nQEcS7GLgCAAAAC0oiAAAALCiJSLa8vLz09ttvy8vLy+4oSGZ4beB+eG3gXnhd/DsMXAEAAIAFRxIBAABgQUkEAACABSURAAAAFpREAAAAWFASAQAAYEFJBPDY4aYMAPDoURIBPHZS++eaA0BSoCQCeGzs3LlThw4dkiT16NFDixYtsjkRgMcRZyMeDjfTBpDsGWN05swZlS9fXq1bt1ZMTIy++OILbd++XWXLlrU7HpKpuLg4ubu72x0DNjLGyOFw6Ny5c4qKilKGDBmUPXt2SVJ8fLzc3DhW9iCURCQ7d3+oQ0NDde7cOXl5ealIkSLOH+y7y5H6rF69Wq1atdK1a9e0ePFiNWvWzO5ISCbuvi9ERUXJ4XAoffr0dkeCze6+Jr799luNGjVK586d0xNPPKHKlSvrvffek8PhoCj+A54ZJDsOh0PffPONatWqpT59+ujpp59W69atNWvWLOdypC7GGBljlDZtWvn5+Sljxoxau3atfvvtN5d1kDrdLQPfffedGjdurKpVq6pKlSpatGiRLl++bHc82MThcGjlypVq166d2rdvr02bNqlKlSqaMWOGunXrJmOM3NzcFB8fb3fUZIsjiUgW/n5aaNeuXapXr57GjBmjli1b6tixY5o5c6Z2796t1157TZ07d7Y5LZLK/f7K//777/Xaa6+pSZMm6t27t0qWLGlDOiQnP/74o5o1a6Y33nhDBQsW1MqVKxUSEqKXX35ZPXv2VKZMmeyOiCR28eJFvfjii3r++efVt29fXblyRWXLllWBAgUUHh6umjVraubMmRxRfACeEdjqu+++U3x8vNzd3XX79m1J0p49e1S4cGF17txZmTJlUqVKlTRgwACVLl1aX3/9tSIjI21OjaRw9698SVq5cqW+/PJL7dixQ7dv39azzz6riRMnasWKFfr444+1f/9+SVK9evW0bNkyO2MjiRljdPPmTc2cOVPdu3fXyJEj1aFDBy1atEgtWrTQF198oY0bN0oSR4xSgbvHvU6cOKEsWbLo5Zdf1tNPP60LFy6oevXqeu6557Rq1SoFBgZq/vz5eumll1zea+CKZwW22bNnj3r37q127drJGCMPDw9JUtq0aXX16lWFhYVJuvNDX7RoUb3yyitatWqV/vjjDztjIwn8/brT/v3765VXXlGfPn3UvXt3DRo0SLGxsWrZsqU++OADrVy5UsHBwapYsaKOHTumZ5991ub0SEoOh0Oenp66du2a0qRJI0mKjY2VJI0aNUrFixfXpEmTJIkikAo4HA4tW7ZML7zwgg4ePKju3burTJky+vzzz1WkSBGNHj1a3t7eKl++vEqUKKGoqCidO3fO7tjJFj8xsE3RokU1cOBAHTlyRB06dHD+BZg3b16Fh4fr22+/1e3bt51lIW/evCpZsiTXnqVwfy+Ie/fu1e7du7VixQrt2rVLzz//vDZv3qzg4GDFxsaqRYsWmj59uurXr68GDRro8OHDSpMmjfOoNFK+u+8HmTJl0vr16yVJXl5eunnzpiSpVq1aun37Nq+JFO7u6+DixYv66KOP1KVLFz3xxBPO5ceOHVNYWJgyZ84sSTp16pReeOEFLVy4ULlz57Yl8+PAw+4ASJ2MMfLx8VHHjh3l5uammTNnqn379po3b55q1qypwYMHq1+/foqLi1Pjxo2VK1cuTZ8+XdHR0fxAp3B3C+KiRYu0cOFCFSxYUOXLl5fD4VD//v2VNm1aLV68WL169dK0adP0zDPPqG7dus5rWm/fvu08Ko2U5+4fEWfPnpWnp6fSpEmjDBky6N1331WNGjXUvHlzffPNN/L09JQkhYaGKkOGDIqLi+N1kYI5HA6tWrVK8+bNk4+Pjxo3bizpr+vdq1atqu3bt+vFF1+Uv7+/Fi9erN27d8vf39/m5MkbA1dgm7sXCsfExGjevHmaNWuWSpYsqfnz58vNzU1jx47VhAkT5O3trcyZM+vixYtasWKFypcvb3d0PGLXr19X3759tWLFCgUEBGjr1q3OZTExMZo+fbqWLFmigIAAffnll/zyT2WWLl2q4cOHKyIiQnXq1FHr1q3VuHFjrVixQl27dlXWrFlVoUIFXb9+Xd9//722bNmiMmXK2B0bj9j69ev19NNPS5I2bNigmjVrOpddunRJn332mdatWyeHw6GxY8fymngIlEQkC9HR0Zo/f75mz57tUhR37Nih8PBwXb9+XVWqVFFAQIDdUfEI3Ovel5cvX9aECRO0YMECdejQQaNHj3Yui4mJ0bhx43T27FnNmDGDa81SsP9+bRw+fFi1a9fWkCFDFB8fr/Xr1+vcuXMaMmSInn/+eZ05c0YjR47UtWvXlC5dOvXr14/R76nIr7/+qtq1a6tZs2b64IMPlCdPHueyuwcmrl+/rrRp09qY8vFBSUSSuvuGv3//fh08eFDp0qVTiRIlVLhwYUVFRenzzz+3FEWkbH+/9URERITSpUun+Ph4eXl56dKlSxozZoy2bNmihg0b6u2333ZuFxsbK09PT25fkYrs27dPy5Yt0/Xr1zV27FhJ0u7duzVlyhT99ttvGjhwoFq1auVcn09cSXnu/g65+2974sQJXb58Wbly5VL69Onl6+urn3/+WQ0aNFC7du30zjvvKFeuXJJ4PfwblEQkibsvM4fDoaVLl6pv377y9/eXj4+PYmNjNWPGDFWuXFmRkZH64osvNHfuXOXKlUvLli3j5tkp2N/L3fjx47Vu3TqFhYWpYcOG6tChg4oXL67w8HCNHTtWW7duVePGjTVs2DCXffAJPCnT+++/rytXruj9999XfHy8Ll++rFdeecX5Opg/f75z3btF8fDhw+revbs6duwoiddGSjNnzhx5e3urefPm8vT01OLFi9WvXz/dvHlTmTJlUsmSJTVhwgQVLFhQP//8sxo2bKj27dvr7bff5izUv2WAR2jMmDHm119/dU7//PPPJlOmTGb69OnGGGO+//574+HhYbJly2Y2bNhgjDEmMjLSTJw40dSuXducPXvWltxIWkOGDDGZM2c2M2fONO+//74JDAw0tWrVMvv27TPGGHPhwgXTv39/U7BgQfPpp5/anBaPWkxMjJk8ebIJDQ11mb9ixQrzzDPPmNy5c5s1a9a4LNu9e7d5/vnnzVNPPWUiIyOTMi6SwO3bt82TTz5pypUrZ7799luzd+9eU6RIETN16lQTEhJipk+fburWrWtKlSpljh07ZowxZv369cbhcJgePXqY27dv2/wdPJ4oiXhkRowYYTJlymQOHTpkjDEmNjbW9OjRw7z11lvGGGPOnj1r8ubNa1q1amWaNm1qsmTJYrZv326MuVMUr1y5Ylt2JJ2lS5eaEiVKmB07dhhjjPnxxx+Nl5eXKVWqlKlSpYo5cOCAMcaYsLAwM3XqVN7sU4m4uDhjjDG//PKL6dmzp3P+6tWrTaNGjcwzzzxj1q5d67JNSEgIf1imQPHx8caYO388NGzY0FSrVs2MGzfOdOzY0eX9YOPGjeapp54yL7/8somOjjbGGLN582Zz8OBBW3KnBJREJLq4uDjz559/msDAQDNmzBhjzJ037z///NPs3r3bbNy40URERJiKFSuabt26GWOMWbZsmXE4HMbNzc1s3LjRzvhIYhs2bDB9+/Y1xhjz3XffmcyZM5tPPvnEfPvttyZLliymRo0aZufOnS7bUBRTh1u3bpn333/f5MuXz/Tp08c5/4cffjBNmjQx9erVM+vWrbMtH5LO3Z/5mJgYU7duXePl5WXKli1rbt265bLehAkTTIkSJcylS5fsiJnicKU3El1YWJgyZMigbNmy6fDhwxo/frzq1aunY8eOqXz58qpRo4a2b98uT09PDRkyRJKUM2dONW7cWMHBwcqaNavN3wEelXt9LFqtWrU0dOhQxcTEaMKECXr99dfVvXt3NWnSRPny5dPx48c1ffp0SX9d28rF5ymT+a9L5D08PNSxY0f16tVLa9asUa9evSRJjRo1Us+ePeXj46NBgwY5P3YPKdfdn/m0adPq+++/V8OGDXXq1CnNmzdPMTExzvUCAwMVFRWl8PBwu6KmKJREJKrXX39drVu3liT169dPa9eu1ZtvvqkePXqoQoUKzvWuXLmibdu2OX+4ly9fLj8/P7377rsqVqyYLdnx6N0dpHLq1CkdPXrUOT9LliwKCwvT4cOHnfcuCw8PV+HChTV16lTNnDlTkhiEkIL9/RNRTp8+rdOnT+vSpUvKli2b2rdvrw4dOmjdunUuRbFTp04qWLCg8uXLZ1dsPGJ3/3AIDw/Xn3/+qRMnTsjb21sLFy5U5cqV9dFHH+mLL75QTEyMrl27pm+++Ube3t7Kli2bzclTCJuPZCIFWbx4sfHz8zO///67McaYTZs2GYfDYXLnzm2Cg4OdgxCMMebEiROmSZMmJkOGDKZ27drGx8fHZTlSjvHjx5sjR444pwcNGmSKFi1q/P39Tdu2bZ3XC12+fNnUqVPHBAUFmWXLlplnnnnG1K9f33lt2t3/ImX54IMPzO7du53TS5cuNblz5zZFixY1BQsWNFu3bjXGGHPp0iUzbtw488QTT7icer577RlSnrvXIv7nP/8x1atXN6VLlzYlSpQwEydONMYYc/36ddOwYUPj6+trSpYsaVq3bm1KlSpldu3aZWfsFIWSiESzaNEiU6FCBRMZGWlWr15tRowYYdasWWOWL19uihcvbrp27WpCQkKc6+/atctMnDjRvPnmm85iiZTl+PHjxuFwmBYtWpgzZ86YL774wuTPn998+eWXZuHChSZnzpymfv36zmsOP//8c1OzZk2TP39+U7duXXPz5k1jDAUxpYqKijJ16tQxfn5+5sCBA+bixYsme/bsZtq0aearr74ybdu2NV5eXmb58uXGmDtFceLEiSZXrlxm0KBBxpi/igRSph9++MF4e3ubDz/80OzevduMGDHCOBwO5+j269evmxYtWhiHw2E++eQTc+7cOZsTpyyURCSa1atXmzJlyphmzZoZh8NhVqxY4Vz25ZdfmuLFi5tu3bqZvXv3umzHm3zKdLfY7dmzx/j6+pqOHTuacePGmdmzZzvXOXHihClUqJB5+umnzf79+40xxly7ds0cO3bMuf1/X5iOlOX06dOmbdu2JkeOHObbb781gwcPdi67fv266dGjh/H29jbfffedMcaYixcvmqlTp5qjR4/aFRlJIC4uzsTFxZkOHTqY4cOHG2OMOXnypClUqJDp3r27cx1j7rxnNG3a1Jw6dcq2vCkVJRGJql27dsbT09PUr1/fhIWFuSxbuHChKV68uHnttddcTi8h5bo7InH37t3Gx8fHOBwOM3r0aJd17hbFevXqmS1btrgs4whiyvX3Pw4//vhj590NGjVq5LLe9evXzWuvvWZ8fX3NN998Y4zhdZFSxcfHO18X4eHhxhhjSpUqZRYsWGAiIiJM7ty5Tbdu3ZzrfPzxx2bTpk225U0NGLiCRHXkyBE1a9ZMZ86c0XvvvadDhw45l7300ksaOXKkli5dqvnz5+vmzZs2JsWjZP7/YnM3NzcZY1S+fHlt27ZN/v7+Wrt2rXPQijFG+fLl09q1a7V161Z99dVXLvvho/ZSrruDkPbs2aO33npLw4cPV+vWrbVx40bt3r1b0p3Xh7e3tz744AMFBQWpZ8+eio6OZgBTCmT+9qlcq1at0lNPPaX9+/crKChIa9asUYkSJfTcc8/p448/lsPhUExMjLZs2aItW7bo9u3blpHxSBx8LB8SxZ49e5QzZ07lyJFDkvTJJ59o8uTJatCggXr27KmiRYs61126dKnKli2rQoUK2RUXj9DfP2rv2rVr8vHx0e3bt+Xh4aHdu3erZs2aaty4scaPH6/8+fM7Pzrt/Pnzypo1K7e3SUX++OMPzZs3T8YYvfPOOzpz5ox69eqlX375RevXr1fp0qWdr4/Y2Fj9+eefzvcYpBx/L4iLFi3Syy+/LEn6+uuv5e7urh49eqhAgQJasmSJcubMqbi4OA0fPlwLFy7UmjVrVLBgQTvjp2iURPxPjDGKiopSoUKF9OSTT2rs2LHOW5jMmDFDkyZNUoMGDRQcHKwiRYrYnBaPmvnbZ+WOGTNGmzZtUmRkpOrVq6dWrVqpePHi2rlzp2rXrq0mTZpo/PjxltuXxMXFURRTgcjISNWtW1cnT55UmzZtNGnSJEnSmTNnFBwcrI0bN2rDhg0qVaoUn8Gcwt39912yZIlatmyppUuX6quvvlLp0qX15ptvavjw4fryyy9VqFAh5cmTR5GRkfr555+1Zs0alS9f3u74KRrncvA/cTgc8vPz0/fff699+/bpnXfe0b59+yRJ3bt31+uvv661a9dq7NixLvfFQ8oTHx/v/EU+YcIEjR07VjVq1FDevHm1du1aNW/eXCEhIapUqZJ++eUX/fTTT3rllVd0/vx5l/1QEFMHPz8/zZw5UxkyZND69eu1d+9eSVKePHn00Ucf6amnnlKZMmV08OBBCmIK53A4tGzZMrVs2VKffvqpgoKCFB0drZMnT0qSRo0apREjRqhUqVIKCwtT4cKFtXnzZgpiUkjqiyDx+Lt70XBsbKzL9I4dO0z27NnNiy++6HLPw8mTJ5snn3zSnD9/PunDIskdOHDAvPzyy87blhhz556ZQUFBplKlSubEiRPGGGO2bdtm6tatyyCEVC4kJMSUKVPGdOnSxTnC3RhjTp06Zdq0acPtsVKJH374wSxYsMA53atXL9OuXTuXdRi9nPQoifhXfvrpJ9OtWzfnPanuFsWdO3caf39/88ILL7jc6ubPP/+0IyaS2FdffWVy5sxpAgICzIYNG1yWrVq1ypQpU8b88MMPlu0oiqnb7t27TYUKFUyXLl3MgQMHnPP5jO7U5+7vknfffddUqVLF+RoYPny4qVChgomIiOC2aUmI0834V27duqVZs2Zp9OjROn/+vBwOh+Lj41WxYkXNmjVL33//vUaNGqUDBw5Ikvz9/W1OjKTQsmVL1apVS2fOnNGPP/7o8pmq9erVU0xMjH799VfLdoxiTt3Kly+v2bNnOy9ZCQ0NlcSlB6mZv7+/rl69Knd3d40cOVJjxozRzJkz5efnx+UHScjD7gBI/owxio+Pl7u7uy5fviwPDw81adJEW7duVfXq1XX79m2NGjXKOeowTZo0evLJJ7V//35lzJhREp+5mxL9fRSzJOcI5kWLFikuLk5LlixRkSJF1K5dO3l4eDhHOmfOnNnG1Eiuypcvr2nTpmngwIHKkCGD3XFgs1KlSilTpkwKDg7W7NmztXXrVlWsWNHuWKkOo5txXz/88INy586tsmXLSrpz65px48YpPDxcpUqVUu/evZU9e3aVL19enTt3Vq9evVSqVCkNHz5c2bJlU+fOnZU2bVqbvws8Cn8viJ999pl27typ69evq3r16urSpYsk6YUXXtCOHTtUtWpVlS9fXtu3b9ehQ4e0f/9+eXjw9ynu7caNG/L29rY7Bmy2bds2BQYGyt3dXdu3b2eQik0oibinCxcuKDAwUHXq1NFbb72lGzduqGrVqho8eLA8PDx04sQJzZo1S/Pnz1eZMmVUv359pU+fXunTp9eJEye0fv16Z7lEyjVo0CAtXLhQTZs2VZYsWTR69GgNHTpUo0ePliS1adNGCxcuVFBQkKpWrapBgwZJ+uuoIwDcS2xsrMaPH68WLVqoWLFidsdJtXiXxj1lz55dS5YsUffu3fXBBx8oQ4YM6t69u4YOHSrpzj3OSpYsqY4dO+rHH3/U5s2b9cMPPygqKkrNmzd3uXk2Uo6/H0Fct26dvv76a3311VeqVq2afvrpJ7m5ualAgQLO9RcsWKDY2FidPXtWAQEBzvkURAAP4uXlpSFDhnBdqs04kogH2r17t1577TVduHBBzz77rKZNm+ZcFhERob59++rGjRtauHChjSnxqL377rvOPxDuFsWFCxfqs88+0+rVq7V06VJ16NBBEyZMUPfu3RUREaH9+/erRo0akqTnn39eJ06cUO/evfXyyy/Ly8vLzm8HAPAQGFKIB6pQoYJmzZolh8OhtWvXOm94K90ZfZYrVy6Fhobq1q1b9oXEIxUaGqphw4bp2WeflfTXSOQMGTI4R7l37NhR48ePV/fu3SVJmzZt0tSpU503w122bJkyZcqkTz/9VLGxsfZ8IwCABKEk4h+VKVNGy5cvV5o0aTRlyhSFhIQ4l126dElZs2bVzZs3bUyIR6lEiRL65ZdfFBISoiZNmjjn58qVS7GxserVq5feeOMNvfrqq5Kk69eva/r06fLx8VHevHmdn8u6du1aLVq0SH5+frZ8HwCAhOF0Mx7anj171L59e8XExKhWrVry8vLSkiVLtGbNGpUrV87ueHgEzP9/pqoxRps3b1bLli1VtmxZrVy5UpL0ySefaNSoUWratKkaNWokDw8PTZkyRRcuXNCuXbvk4eHhcgslAMDjg5KIBNm/f79eeOEFxcbGqkePHmrdurXy5ctndyw8Av99H0Tpzmnk9u3bq0CBAlq7dq0kafLkyVq1apXWrl2rKlWqKHPmzFq8eLHSpEmjuLg4yiEAPKYoiUiwXbt2aciQIVqwYIGyZs1qdxw8An8viHPnzlVoaKhu3ryp6tWrK1u2bOratavy5s2r1atXS5Kio6MVHh6uzJkzOz8RgdvcAMDjjZKIf4Ub3qYOgwYN0vz58/Xyyy/r9OnT2rdvnxo2bKgXX3xRrVq1cjn1/Hd3T1MDAB5fDFzBv0JBTPl+/PFHLVmyRMuXL9cHH3ygli1b6uTJk6patapq1qypxYsX6/Dhw3ryySct21IQAeDxR0kEcE/nzp1TQECAKleurCVLlqhz586aPHmyWrdurRs3biguLk4zZ85Unjx5FB8fb3dcAEAioyQCuCcPDw8FBARo5cqV6tSpk8aNG+e8zc3KlSv1008/qXTp0lq2bJnc3NwoigCQwnBNIoB7+v3331W2bFndunVLn332mTp27Cjpzn0Qn3/+eeXOnVuzZ8/m1DIApFAcSQRwT8WLF9eCBQvk7e2t0NBQrV+/XuvWrVOzZs0UFhamGTNmOO+hCABIeTiSCOC+4uLitHjxYg0cOFCSlCNHDuXKlUvffPMN90EEgBSOkgjgH128eFFXr16Vl5eXAgICuA8iAKQClEQACXavT2MBAKQslEQAAABYcCgAAAAAFpREAAAAWFASAQAAYEFJBAAAgAUlEQAAABaURAAAAFhQEgEAAGBBSQSAJJA/f35NnjzZOe1wOPTtt98meY4RI0aoXLly912+fv16ORwOXb169aH3WadOHfXt2/d/yjV37lxlyJDhf9oHgMRFSQQAG4SFhalRo0YPte4/FTsAeBT44FUAeEg3b96Up6dnouwrR44cibIfAHhUOJIIIFWqU6eOgoODFRwcLH9/f2XJkkXDhg3T3z+pNH/+/Bo9erTat28vPz8/devWTZK0adMm1axZU2nTplVAQIB69+6ta9euObcLDw/Xc889p7Rp06pAgQJasGCB5fH/+3TzmTNn1Lp1a2XKlEk+Pj6qVKmStm3bprlz52rkyJEKCQmRw+GQw+HQ3LlzJUlXr15Vly5dlDVrVvn5+enpp59WSEiIy+OMHTtW2bNnl6+vrzp37qwbN24k6Hm6fPmyWrdurdy5cytdunQqXbq0Fi5caFnv9u3bD3wuY2NjNWDAAOXOnVs+Pj6qUqWK1q9fn6AsAJIWJRFAqjVv3jx5eHho+/btmjJlij744APNnj3bZZ0JEyaobNmy2rNnj4YNG6ajR4+qYcOGat68ufbt26evvvpKmzZtUnBwsHObjh076vTp01q3bp2WLFmijz/+WOHh4ffNER0drdq1a+vs2bNavny5QkJCNGjQIMXHx6tVq1bq37+/nnjiCYWFhSksLEytWrWSJLVo0ULh4eFauXKldu3apQoVKqhu3bq6cuWKJGnx4sUaMWKE3nvvPe3cuVM5c+bUxx9/nKDn6MaNG6pYsaJWrFihAwcOqFu3bmrXrp22b9+eoOcyODhYW7du1aJFi7Rv3z61aNFCDRs21JEjRxKUB0ASMgCQCtWuXduUKFHCxMfHO+cNHjzYlChRwjmdL18+ExQU5LJd586dTbdu3Vzmbdy40bi5uZnr16+bQ4cOGUlm+/btzuWhoaFGkpk0aZJzniSzbNkyY4wxM2bMML6+vuby5cv3zPr222+bsmXLWh7Tz8/P3Lhxw2V+oUKFzIwZM4wxxgQGBpoePXq4LK9SpYplX3+3bt06I8n8+eef912nSZMmpn///s7pf3ouT548adzd3c3Zs2dd9lO3bl0zZMgQY4wxc+bMMf7+/vd9TABJj2sSAaRaVatWlcPhcE4HBgZq4sSJiouLk7u7uySpUqVKLtuEhIRo3759LqeQjTGKj4/X8ePHdfjwYXl4eKhixYrO5cWLF3/gyN29e/eqfPnyypQp00NnDwkJUXR0tDJnzuwy//r16zp69KgkKTQ0VK+++qrL8sDAQK1bt+6hHycuLk7vvfeeFi9erLNnz+rmzZuKjY1VunTpXNZ70HO5f/9+xcXFqWjRoi7bxMbGWvIDSD4oiQDwAD4+Pi7T0dHR6t69u3r37m1ZN2/evDp8+HCCHyNt2rQJ3iY6Olo5c+a853V9iXkrmfHjx2vKlCmaPHmySpcuLR8fH/Xt21c3b95MUFZ3d3ft2rXLWb7vSp8+faJlBZC4KIkAUq1t27a5TP/6668qUqSIpcj8XYUKFXTw4EEVLlz4nsuLFy+u27dva9euXXryySclSYcOHXrgfQfLlCmj2bNn68qVK/c8mujp6am4uDhLjvPnz8vDw0P58+e/535LlCihbdu2qX379i7fY0Js3rxZzZo1U9u2bSVJ8fHxOnz4sEqWLOmy3oOey/LlyysuLk7h4eGqWbNmgh4fgH0YuAIg1Tp16pT69eunQ4cOaeHChfrwww/Vp0+fB24zePBgbdmyRcHBwdq7d6+OHDmi//znP86BK8WKFVPDhg3VvXt3bdu2Tbt27VKXLl0eeLSwdevWypEjh4KCgrR582YdO3ZM33zzjbZu3Srpzijr48ePa+/evbp06ZJiY2NVr149BQYGKigoSKtWrdKJEye0ZcsWDR06VDt37pQk9enTR5999pnmzJmjw4cP6+2339Zvv/2WoOeoSJEiWr16tbZs2aLQ0FB1795dFy5cSNBzWbRoUbVp00bt27fX0qVLdfz4cW3fvl1jxozRihUrEpQHQNKhJAJItdq3b6/r16+rcuXK6tmzp/r06eO8zc39lClTRhs2bNDhw4dVs2ZNlS9fXsOHD1euXLmc68yZM0e5cuVS7dq19cILL6hbt27Kli3bfffp6empVatWKVu2bGrcuLFKly6tsWPHOo9oNm/eXA0bNtRTTz2lrFmzauHChXI4HPrhhx9Uq1YtderUSUWLFtVLL72kkydPKnv27JKkVq1aadiwYRo0aJAqVqyokydP6rXXXkvQc/TWW2+pQoUKatCggerUqeMsswl9LufMmaP27durf//+KlasmIKCgrRjxw7lzZs3QXkAJB2HMX+7kRUApBJ16tRRuXLlXD4qDwDwF44kAgAAwIKSCAAAAAtONwMAAMCCI4kAAACwoCQCAADAgpIIAAAAC0oiAAAALCiJAAAAsKAkAgAAwIKSCAAAAAtKIgAAACz+DxPDrUIKvNdaAAAAAElFTkSuQmCC","text/plain":["<Figure size 1000x700 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# TODO\n","\n","from torchmetrics import ConfusionMatrix\n","from mlxtend.plotting import plot_confusion_matrix\n","\n","# Setup confusion matrix instance\n","confmat = ConfusionMatrix(task= \"multiclass\", num_classes=len(class_names))\n","confmat_tensor = confmat(preds=test_preds,\n","                         target=y_test_true)\n","\n","# Plot the confusion matrix\n","fig, ax = plot_confusion_matrix(\n","    conf_mat=confmat_tensor.numpy(), # matplotlib likes working with NumPy\n","    class_names=class_names,\n","    figsize=(10, 7)\n",")"]},{"cell_type":"markdown","metadata":{},"source":["The metrics are just mid considering that the model is almost 300MB in size."]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:34:01.887830Z","iopub.status.busy":"2024-02-14T17:34:01.887435Z","iopub.status.idle":"2024-02-14T17:34:01.905199Z","shell.execute_reply":"2024-02-14T17:34:01.904066Z","shell.execute_reply.started":"2024-02-14T17:34:01.887799Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train data:\n","Dataset ImageFolder\n","    Number of datapoints: 1224\n","    Root location: /kaggle/working/train\n","    StandardTransform\n","Transform: Compose(\n","               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=warn)\n","               ToTensor()\n","           )\n","Test data:\n","Dataset ImageFolder\n","    Number of datapoints: 280\n","    Root location: /kaggle/working/val\n","    StandardTransform\n","Transform: Compose(\n","               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=warn)\n","               ToTensor()\n","           )\n"]}],"source":["from torchvision import datasets\n","from torchvision import transforms \n","\n","# # Create simple transform\n","data_transform = transforms.Compose([ \n","    transforms.Resize((64, 64)),\n","    transforms.ToTensor(),\n","    \n","])\n","\n","# Use ImageFolder to create dataset(s)\n","train_data = datasets.ImageFolder(root=train_dir, # target folder of images\n","                                  transform=data_transform, # transforms to perform on data (images)\n","                                  target_transform=None) # transforms to perform on labels (if necessary)\n","\n","test_data = datasets.ImageFolder(root=test_dir, \n","                                 transform=data_transform)\n","\n","print(f\"Train data:\\n{train_data}\\nTest data:\\n{test_data}\")"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:34:04.648096Z","iopub.status.busy":"2024-02-14T17:34:04.647708Z","iopub.status.idle":"2024-02-14T17:34:04.656902Z","shell.execute_reply":"2024-02-14T17:34:04.655851Z","shell.execute_reply.started":"2024-02-14T17:34:04.648068Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(<torch.utils.data.dataloader.DataLoader at 0x7fcb18440dc0>,\n"," <torch.utils.data.dataloader.DataLoader at 0x7fcb18442ce0>)"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["# Turn train and test Datasets into DataLoaders\n","from torch.utils.data import DataLoader\n","\n","train_dataloader = DataLoader(dataset=train_data, \n","                              batch_size=1, # how many samples per batch?\n","                              num_workers=1, # how many subprocesses to use for data loading? (higher = more)\n","                              shuffle=True) # shuffle the data?\n","\n","test_dataloader = DataLoader(dataset=test_data, \n","                             batch_size=1, \n","                             num_workers=1, \n","                             shuffle=False) # don't usually need to shuffle testing data\n","\n","train_dataloader, test_dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T17:34:11.225883Z","iopub.status.busy":"2024-02-14T17:34:11.225510Z","iopub.status.idle":"2024-02-14T17:34:12.150618Z","shell.execute_reply":"2024-02-14T17:34:12.149247Z","shell.execute_reply.started":"2024-02-14T17:34:11.225854Z"},"trusted":true},"outputs":[],"source":["# checking out model by doing a dummy forward pass: \n","#Required when using a pretrained model as we may not know in advance the specific matrices dims\n","# 1. Get a batch of images and labels from the DataLoader\n","img_batch, label_batch = next(iter(train_dataloader))\n","\n","# 2. Get a single image from the batch and unsqueeze the image so its shape fits the model\n","img_single, label_single = img_batch[0].unsqueeze(dim=0), label_batch[0]\n","print(f\"Single image shape: {img_single.shape}\\n\")\n","\n","# 3. Perform a forward pass on a single image\n","model_0.eval()\n","with torch.inference_mode():\n","    pred = model_0(img_single.to(device))\n","    \n","# 4. Print out what's happening and convert model logits -> pred probs -> pred label\n","print(f\"Output logits:\\n{pred}\\n\")\n","print(f\"Output prediction probabilities:\\n{torch.softmax(pred, dim=1)}\\n\")\n","print(f\"Output prediction label:\\n{torch.argmax(torch.softmax(pred, dim=1), dim=1)}\\n\")\n","print(f\"Actual label:\\n{label_single}\")"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":674157,"sourceId":1185810,"sourceType":"datasetVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
